{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../src/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/disambiguation/entity-linking/disambiguation/src\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[0m\u001b[01;34mclustering\u001b[0m/  \u001b[01;34mdata\u001b[0m/  \u001b[01;34mfeature\u001b[0m/  \u001b[01;34mkpe\u001b[0m/  \u001b[01;34mmodel\u001b[0m/  \u001b[01;34mpipeline\u001b[0m/\r\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from data.corpus_builder import DirectoryBackedCorpus, FileBackedCorpus\n",
      "from gensim import corpora, models\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = \"/home/disambiguation/entity-linking/disambiguation/data/toy-corpus.txt\"\n",
      "description = \"Toy corpus example from  Deerwester et al. (1990)\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = FileBackedCorpus(path, description, no_below=2, no_above=1.0)\n",
      "corpus.initialize_dictionary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Toy corpus example from  Deerwester et al. (1990):\n",
        "\t0 -->> Human machine interface for lab abc computer applications\n",
        "\t1 -->> A survey of user opinion of computer system response time\n",
        "\t2 -->> The EPS user interface management system\n",
        "\t3 -->> System and human system engineering testing of EPS\n",
        "\t4 -->> Relation of user perceived response time to error measurement\n",
        "\t5 -->> The generation of random binary unordered trees\n",
        "\t6 -->> The intersection graph of paths in trees\n",
        "\t7 -->> Graph minors IV Widths of trees and well quasi ordering\n",
        "\t8 -->> Graph minors A survey\n",
        "\t...\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for doc in corpus.documents: print doc.get_tokens()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'human', u'machine', u'interface', u'for', u'lab', u'abc', u'computer', u'applications']\n",
        "[u'a', u'survey', u'of', u'user', u'opinion', u'of', u'computer', u'system', u'response', u'time']\n",
        "[u'the', u'eps', u'user', u'interface', u'management', u'system']\n",
        "[u'system', u'and', u'human', u'system', u'engineering', u'testing', u'of', u'eps']\n",
        "[u'relation', u'of', u'user', u'perceived', u'response', u'time', u'to', u'error', u'measurement']\n",
        "[u'the', u'generation', u'of', u'random', u'binary', u'unordered', u'trees']\n",
        "[u'the', u'intersection', u'graph', u'of', u'paths', u'in', u'trees']\n",
        "[u'graph', u'minors', u'iv', u'widths', u'of', u'trees', u'and', u'well', u'quasi', u'ordering']\n",
        "[u'graph', u'minors', u'a', u'survey']\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus.dictionary.save('/tmp/deerwester.dict')\n",
      "corpora.MmCorpus.serialize('/tmp/deerwester.mm', corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = corpora.Dictionary.load('/tmp/deerwester.dict')\n",
      "gcorpus = corpora.MmCorpus('/tmp/deerwester.mm')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dictionary.token2id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'minors': 0, 'graph': 1, 'system': 2, 'trees': 3, 'eps': 4, 'computer': 5, 'survey': 6, 'user': 7, 'human': 8, 'time': 9, 'interface': 10, 'response': 11}\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dictionary\n",
      "print gcorpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(12 unique tokens)\n",
        "MmCorpus(9 documents, 12 features, 28 non-zero entries)\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tfidf = models.TfidfModel(gcorpus)\n",
      "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tfidf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TfidfModel(num_docs=9, num_nnz=28)\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc_bow = [(5, 1), (8, 1)]\n",
      "print tfidf[doc_bow] # step 2 -- use the model to transform vectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(5, 0.7071067811865476), (8, 0.7071067811865476)]\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus_tfidf = tfidf[corpus]\n",
      "for doc in corpus_tfidf: print doc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(5, 0.5773502691896257), (8, 0.5773502691896257), (10, 0.5773502691896257)]\n",
        "[(2, 0.3244870206138555), (5, 0.44424552527467476), (6, 0.44424552527467476), (7, 0.3244870206138555), (9, 0.44424552527467476), (11, 0.44424552527467476)]\n",
        "[(2, 0.4170757362022777), (4, 0.5710059809418182), (7, 0.4170757362022777), (10, 0.5710059809418182)]\n",
        "[(2, 0.7184811607083769), (4, 0.49182558987264147), (8, 0.49182558987264147)]\n",
        "[(7, 0.45889394536615247), (9, 0.6282580468670046), (11, 0.6282580468670046)]\n",
        "[(3, 1.0)]\n",
        "[(1, 0.7071067811865475), (3, 0.7071067811865475)]\n",
        "[(0, 0.695546419520037), (1, 0.5080429008916749), (3, 0.5080429008916749)]\n",
        "[(0, 0.6282580468670046), (1, 0.45889394536615247), (6, 0.6282580468670046)]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2) # initialize an LSI transformation\n",
      "corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, topic in enumerate(lsi.print_topics(2)): print \"%d -->> %s\" % (i, topic)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 -->> -0.703*\"trees\" + -0.538*\"graph\" + -0.402*\"minors\" + -0.187*\"survey\" + -0.061*\"system\" + -0.060*\"time\" + -0.060*\"response\" + -0.058*\"user\" + -0.049*\"computer\" + -0.035*\"interface\"\n",
        "1 -->> -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for doc in corpus_lsi: # both bow->tfidf and tfidf->lsi transformations are actually executed here, on the fly\n",
      "    print doc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, -0.066007833960903289), (1, -0.52007033063618502)]\n",
        "[(0, -0.19667592859142358), (1, -0.7609563167700053)]\n",
        "[(0, -0.089926399724463854), (1, -0.72418606267525176)]\n",
        "[(0, -0.075858476521781459), (1, -0.63205515860034356)]\n",
        "[(0, -0.10150299184980008), (1, -0.57373084830029608)]\n",
        "[(0, -0.70321089393783132), (1, 0.16115180214025701)]\n",
        "[(0, -0.87747876731198327), (1, 0.16758906864659301)]\n",
        "[(0, -0.90986246868185816), (1, 0.14086553628718909)]\n",
        "[(0, -0.61658253505692806), (1, -0.053929075663894405)]\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi.save('/tmp/model.lsi') # same for tfidf, lda, ...\n",
      "lsi = models.LsiModel.load('/tmp/model.lsi')\n",
      "print lsi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LsiModel(num_terms=12, num_topics=2, decay=1.0, chunksize=20000)\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda = models.ldamodel.LdaModel(corpus, id2word=corpus.dictionary, num_topics=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes to improve accuracy\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda.save('/tmp/model.lda') # same for tfidf, lda, ...\n",
      "lda = models.LsiModel.load('/tmp/model.lda')\n",
      "print lda"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LdaModel(num_terms=12, num_topics=2, decay=0.5, chunksize=2000, alpha=0.5)\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " hdp = models.hdpmodel.HdpModel(corpus, id2word=corpus.dictionary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hdp.save('/tmp/model.hdp') # same for tfidf, lda, ...\n",
      "hdp = models.LsiModel.load('/tmp/model.hdp')\n",
      "print hdp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<gensim.models.hdpmodel.HdpModel object at 0x24a6a50>\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hdp.print_topics()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}