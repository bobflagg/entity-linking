{
 "metadata": {
  "name": "data-utility-test"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../src/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/opt/disambiguation/entity-linking/disambiguation/src\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "u'/opt/disambiguation/entity-linking/disambiguation/src'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from data.corpus_builder import DirectoryBackedCorpus, FileBackedCorpus\n",
      "from gensim import corpora, models\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = \"/home/disambiguation/data-sets/mycorpus.txt\"\n",
      "description = \"Toy corpus example from  Deerwester et al. (1990)\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = FileBackedCorpus(path, description, no_below=2, no_above=1.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Toy corpus example from  Deerwester et al. (1990):\n",
        "\t0 -->> Human machine interface for lab abc computer applications\n",
        "\t1 -->> A survey of user opinion of computer system response time\n",
        "\t2 -->> The EPS user interface management system\n",
        "\t3 -->> System and human system engineering testing of EPS\n",
        "\t4 -->> Relation of user perceived response time to error measurement\n",
        "\t5 -->> The generation of random binary unordered trees\n",
        "\t6 -->> The intersection graph of paths in trees\n",
        "\t7 -->> Graph minors IV Widths of trees and well quasi ordering\n",
        "\t8 -->> Graph minors A survey\n",
        "\t...\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for doc in corpus.documents: print doc.get_tokens()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'human', u'machine', u'interface', u'for', u'lab', u'abc', u'computer', u'applications']\n",
        "[u'a', u'survey', u'of', u'user', u'opinion', u'of', u'computer', u'system', u'response', u'time']\n",
        "[u'the', u'eps', u'user', u'interface', u'management', u'system']\n",
        "[u'system', u'and', u'human', u'system', u'engineering', u'testing', u'of', u'eps']\n",
        "[u'relation', u'of', u'user', u'perceived', u'response', u'time', u'to', u'error', u'measurement']\n",
        "[u'the', u'generation', u'of', u'random', u'binary', u'unordered', u'trees']\n",
        "[u'the', u'intersection', u'graph', u'of', u'paths', u'in', u'trees']\n",
        "[u'graph', u'minors', u'iv', u'widths', u'of', u'trees', u'and', u'well', u'quasi', u'ordering']\n",
        "[u'graph', u'minors', u'a', u'survey']\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus.dictionary.save('/tmp/deerwester.dict')\n",
      "corpora.MmCorpus.serialize('/tmp/deerwester.mm', corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'NoneType' object has no attribute 'save'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-9-31def9f9b06a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/deerwester.dict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMmCorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/deerwester.mm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'save'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = corpora.Dictionary.load('/tmp/deerwester.dict')\n",
      "gcorpus = corpora.MmCorpus('/tmp/deerwester.mm')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dictionary.token2id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'minors': 0, 'graph': 1, 'system': 2, 'trees': 3, 'eps': 4, 'computer': 5, 'survey': 6, 'user': 7, 'human': 8, 'time': 9, 'interface': 10, 'response': 11}\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dictionary\n",
      "print gcorpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(12 unique tokens)\n",
        "MmCorpus(9 documents, 12 features, 28 non-zero entries)\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tfidf = models.TfidfModel(gcorpus)\n",
      "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tfidf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TfidfModel(num_docs=9, num_nnz=28)\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc_bow = [(5, 1), (8, 1)]\n",
      "print tfidf[doc_bow] # step 2 -- use the model to transform vectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(5, 0.7071067811865476), (8, 0.7071067811865476)]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus_tfidf = tfidf[corpus]\n",
      "for doc in corpus_tfidf: print doc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(5, 0.5773502691896257), (8, 0.5773502691896257), (10, 0.5773502691896257)]\n",
        "[(2, 0.3244870206138555), (5, 0.44424552527467476), (6, 0.44424552527467476), (7, 0.3244870206138555), (9, 0.44424552527467476), (11, 0.44424552527467476)]\n",
        "[(2, 0.4170757362022777), (4, 0.5710059809418182), (7, 0.4170757362022777), (10, 0.5710059809418182)]\n",
        "[(2, 0.7184811607083769), (4, 0.49182558987264147), (8, 0.49182558987264147)]\n",
        "[(7, 0.45889394536615247), (9, 0.6282580468670046), (11, 0.6282580468670046)]\n",
        "[(3, 1.0)]\n",
        "[(1, 0.7071067811865475), (3, 0.7071067811865475)]\n",
        "[(0, 0.695546419520037), (1, 0.5080429008916749), (3, 0.5080429008916749)]\n",
        "[(0, 0.6282580468670046), (1, 0.45889394536615247), (6, 0.6282580468670046)]\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2) # initialize an LSI transformation\n",
      "corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, topic in enumerate(lsi.print_topics(2)): print \"%d -->> %s\" % (i, topic)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 -->> -0.703*\"trees\" + -0.538*\"graph\" + -0.402*\"minors\" + -0.187*\"survey\" + -0.061*\"system\" + -0.060*\"response\" + -0.060*\"time\" + -0.058*\"user\" + -0.049*\"computer\" + -0.035*\"interface\"\n",
        "1 -->> -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for doc in corpus_lsi: # both bow->tfidf and tfidf->lsi transformations are actually executed here, on the fly\n",
      "    print doc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, -0.066007833960903123), (1, -0.52007033063618457)]\n",
        "[(0, -0.1966759285914248), (1, -0.76095631677000519)]\n",
        "[(0, -0.089926399724463368), (1, -0.72418606267525076)]\n",
        "[(0, -0.075858476521780793), (1, -0.63205515860034267)]\n",
        "[(0, -0.10150299184980111), (1, -0.57373084830029619)]\n",
        "[(0, -0.70321089393783087), (1, 0.16115180214025737)]\n",
        "[(0, -0.87747876731198293), (1, 0.1675890686465932)]\n",
        "[(0, -0.90986246868185794), (1, 0.14086553628718926)]\n",
        "[(0, -0.6165825350569285), (1, -0.053929075663894446)]\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi.save('/tmp/model.lsi') # same for tfidf, lda, ...\n",
      "lsi = models.LsiModel.load('/tmp/model.lsi')\n",
      "print lsi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LsiModel(num_terms=12, num_topics=2, decay=1.0, chunksize=20000)\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda = models.ldamodel.LdaModel(corpus, id2word=corpus.dictionary, num_topics=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda.save('/tmp/model.lda') # same for tfidf, lda, ...\n",
      "lda = models.LsiModel.load('/tmp/model.lda')\n",
      "print lda"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LdaModel(num_terms=12, num_topics=2, decay=0.5, chunksize=2000, alpha=0.5)\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}