{
 "metadata": {
  "name": "test-kore"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd '/opt/disambiguation/entity-linking/disambiguation/src/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/opt/disambiguation/entity-linking/disambiguation/src\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs\n",
      "import ConfigParser\n",
      "import pickle\n",
      "import kore.domain as dm\n",
      "import kore.data_collector as dc\n",
      "\n",
      "\n",
      "config_path = \"/home/disambiguation/config/kb-population.cfg\"\n",
      "config = ConfigParser.ConfigParser()\n",
      "config.read(config_path) \n",
      "home = config.get('main','home')\n",
      "g = \"js\"\n",
      "max_keyphrases = 20"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(dm)\n",
      "reload(dc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 166,
       "text": [
        "<module 'kore.data_collector' from 'kore/data_collector.pyc'>"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = dc.collect_group_data(home, config, g)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading group js data took 0.380 s\n"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"# mentions:\", dataset.next_mention_index\n",
      "print \"# phrases:\", dataset.next_phrase_index\n",
      "print \"# tokens:\", dataset.next_token_index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# mentions: 193\n",
        "# phrases: 3564\n",
        "# tokens: 3394\n"
       ]
      }
     ],
     "prompt_number": 168
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mentions = dataset.mentions()\n",
      "for mention in mentions: mention.trim_keyphrases(max_keyphrases)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dataset.phrase_map['general motors corp.'].tokens\n",
      "print dataset.phrase_map['general motors'].tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'general', u'motors', u'corp']\n",
        "[u'general', u'motors']\n"
       ]
      }
     ],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mentions[3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[3] js-16::971105-177_UEM::1: John Smith -->> [general motors corp., union pacific corp., dallas, dallas based union pacific corp., pacific, southern pacific rail corp., city public service of san antonio, san antonio, texas, mark werner, u.s., washington, bloomberg, union pacific, andy ramirez, austin, austin, texas, austin electric utility, barnett banks, lynn reaser, jacksonville, florida]\n"
       ]
      }
     ],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mentions[3].get_phi()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "18.16\n"
       ]
      }
     ],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keyword_corpus = [mention.keyword_doc() for mention in mentions]\n",
      "    #for keyphrase in mention.keyphrases: print keyphrase.phrase.tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "count_vectorizer = CountVectorizer()\n",
      "count_vectorizer.fit_transform(keyword_corpus)\n",
      "freq_term_matrix = count_vectorizer.transform(keyword_corpus)\n",
      "print freq_term_matrix.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(193, 1914)\n"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "tfidf = TfidfTransformer(norm=\"l2\")\n",
      "tfidf.fit(freq_term_matrix)\n",
      "print \"IDF:\", tfidf.idf_.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "IDF: (1914,)\n"
       ]
      }
     ],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "def build_gamma(mentions):\n",
      "    keyword_corpus = [mention.keyword_doc() for mention in mentions]\n",
      "    count_vectorizer = CountVectorizer()\n",
      "    count_vectorizer.fit_transform(keyword_corpus)\n",
      "    freq_term_matrix = count_vectorizer.transform(keyword_corpus)\n",
      "    tfidf = TfidfTransformer(norm=\"l2\")\n",
      "    tfidf.fit(freq_term_matrix)\n",
      "    return {token:tfidf.idf_[i] for token, i in count_vectorizer.vocabulary_.iteritems()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gamma = build_gamma(mentions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gamma['gm']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 178,
       "text": [
        "1.8984103065963067"
       ]
      }
     ],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def po(p, q, gamma):\n",
      "    p_tokens = set(p.tokens)\n",
      "    q_tokens = set(q.tokens)\n",
      "    numerator = sum(gamma[w] for w in p_tokens & q_tokens)\n",
      "    denominator = sum(gamma[w] for w in p_tokens | q_tokens)\n",
      "    return numerator / denominator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = dataset.phrase_map['general motors corp.']\n",
      "q = dataset.phrase_map['general motors']\n",
      "print 'po(\"%s\", \"%s\") = %0.2f' % (p, q, po(p, q, gamma))\n",
      "print 'po(\"%s\", \"%s\") = %0.2f' % (p, p, po(p, p, gamma))\n",
      "print 'po(\"%s\", \"%s\") = %0.2f' % (q, q, po(q, q, gamma))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "po(\"general motors corp.\", \"general motors\") = 0.67\n",
        "po(\"general motors corp.\", \"general motors corp.\") = 1.00\n",
        "po(\"general motors\", \"general motors\") = 1.00\n"
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def kore(e, f, gamma):\n",
      "    numerator = 0.0\n",
      "    for p in e.keyphrases:\n",
      "        for q in f.keyphrases:\n",
      "            x = po(p.phrase, q.phrase, gamma)\n",
      "            numerator += x * x * min(p.proximity, q.proximity)\n",
      "    return numerator / (e.get_phi() + f.get_phi())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e = mentions[121]\n",
      "f = mentions[190]\n",
      "print e\n",
      "print f\n",
      "print kore(e, f, gamma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[121] js-19::970227-644_UEM::1: John Smith -->> [south wales, labor candidate for parliament, labor party, barry island, britain, barry, cardiff, glamorgan, vale of glamorgan, tony blair, london, stratford place, walter sweeney, blair, william hague, labor government, welsh conservatives, wales, office of king sturge & co., croydon]\n",
        "[190] js-24::970527-468_UEM::1: John Smith -->> [reed, reed, capitol police, capitol police force, fbi, federal law enforcement training center, glynco, ga., congress, ernest m. riddle, democratic club, talmadge w. reed, ronald kessler, new york times special features, new york times, riddle, paul r. mcgill, rayburn, mcgill, george holmes, alabama]\n",
        "0.0\n"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# http://pyevolve.sourceforge.net/wordpress/?p=1747\n",
      "# http://scikit-learn.org/stable/modules/feature_extraction.html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}