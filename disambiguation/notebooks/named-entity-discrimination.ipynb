{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../src"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/CERT/rflagg/disambiguation/entity-linking/disambiguation/src\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import data.corpus_builder as cb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(cb)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 151,
       "text": [
        "<module 'data.corpus_builder' from 'data/corpus_builder.pyc'>"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = '/home/disambiguation/data/johnSmith'\n",
      "form = \"John Smith\"\n",
      "components = 80"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "context_corpus = cb.build_discrimination_corpus(path, form)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "context_corpus.initialize_dictionary()\n",
      "from gensim import corpora, models\n",
      "context_tfidf = models.TfidfModel(context_corpus)\n",
      "context_corpus_tfidf = context_tfidf[context_corpus]\n",
      "labels = [document.label for document in context_corpus.documents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nlabels = len(labels)\n",
      "ndocs = len(context_corpus)\n",
      "nfeatures = len(context_corpus.dictionary)\n",
      "print \"ndocs: %s; nlabels: %s; nfeatures: %s\" % (ndocs, nlabels, nfeatures)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ndocs: 197; nlabels: 197; nfeatures: 564\n"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(context_corpus_tfidf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "197\n"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpora.MmCorpus.serialize('/tmp/johnSmith.mm', context_corpus_tfidf)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for doc in context_corpus_tfidf: \n",
      "    print doc\n",
      "    break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(114, 0.27552964812365277), (155, 0.26612260278047833), (197, 0.3479330268131783), (200, 0.1957256984582339), (213, 0.249844140767546), (217, 0.1957256984582339), (282, 0.2860458301123087), (333, 0.32800979948134784), (393, 0.29796809394438406), (409, 0.2042354060796088), (436, 0.2360808972435146), (467, 0.19987920789875185), (473, 0.29796809394438406), (492, 0.29796809394438406)]\n"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nrow = len(context_corpus)\n",
      "ncol = len(context_corpus.dictionary)\n",
      "print nrow, ncol"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "197 564\n"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = np.zeros((nrow,ncol))\n",
      "position = 0\n",
      "for doc in context_corpus_tfidf: \n",
      "    for col, value in doc: data[position, col] = value\n",
      "    position += 1\n",
      "data = np.mat(data)\n",
      "np.savetxt(\"/tmp/context_corpus_tfidf.csv\", data, delimiter=\",\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn.preprocessing import Normalizer\n",
      "lsa = TruncatedSVD(components)\n",
      "X = lsa.fit_transform(data)\n",
      "X = Normalizer(copy=False).fit_transform(X)\n",
      "print X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(197, 80)\n"
       ]
      }
     ],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savetxt(\"/tmp/X.csv\", X, delimiter=\",\")\n",
      "f = open(\"/tmp/labels.csv\", 'w')\n",
      "for label in labels: f.write(\"%s\\n\" % label)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from nltk.corpus import stopwords\n",
      "import re\n",
      "from scipy.sparse import csc_matrix, lil_matrix\n",
      "import string"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NUMBER_PATTERN = \"^[\\d, \\.]+$\"\n",
      "english_stopwords = stopwords.words('english')\n",
      "for s in string.punctuation: english_stopwords.append(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_skip_word(word):\n",
      "    if word in english_stopwords: return True\n",
      "    if re.match(NUMBER_PATTERN, word): return True\n",
      "    return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = CountVectorizer(min_df=1)\n",
      "analyze = vectorizer.build_analyzer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_counts = {}\n",
      "for document in context_corpus.documents:\n",
      "    for word in analyze(document.get_text()):\n",
      "        if not is_skip_word(word):\n",
      "            if not (word in word_counts): word_counts[word] = 0\n",
      "            word_counts[word] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = [word for word in word_counts.keys() if word_counts[word] > 0]\n",
      "nwords = len(words)\n",
      "words.sort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index_map = {word:i for i, word in enumerate(words)}\n",
      "sum_counts = float(sum(word_counts.values()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#bigram_vectorizer = CountVectorizer(ngram_range=(2,3), token_pattern=r'\\b\\w+\\b', min_df=2)\n",
      "bigram_vectorizer = CountVectorizer(ngram_range=(2,3), min_df=1)\n",
      "bigram_analyze = bigram_vectorizer.build_analyzer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_bigram(item):\n",
      "    parts = item.split()\n",
      "    last = 1\n",
      "    if len(parts) == 3: last = 2\n",
      "    start = parts[0]\n",
      "    end = parts[last] \n",
      "    if is_skip_word(start) or is_skip_word(end): return None\n",
      "    return (start, end)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_counts = {}\n",
      "for document in context_corpus.documents:\n",
      "    for item in bigram_analyze(document.get_text()):\n",
      "        bigram = get_bigram(item)\n",
      "        if bigram:\n",
      "            if not (bigram in bigram_counts): bigram_counts[bigram] = 0\n",
      "            bigram_counts[bigram] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigrams = [bigram for bigram in bigram_counts.keys() if bigram_counts[bigram] > 1]\n",
      "nbigrams = len(bigrams)\n",
      "bigrams.sort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_words = set()\n",
      "for u, v in bigrams: \n",
      "    bigram_words.add(u)\n",
      "    bigram_words.add(v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_words = list(bigram_words)\n",
      "bigram_words.sort()\n",
      "bigram_index_map = {word:i for i, word in enumerate(bigram_words)}\n",
      "nbigram_words = len(bigram_words)\n",
      "bigram_sum_counts = float(sum(bigram_counts.values()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"nwords: %d; nbigrams: %d; nbigram_words: %d\" % (nwords,nbigrams, nbigram_words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nwords: 2886; nbigrams: 1443; nbigram_words: 843\n"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "S = lil_matrix((nbigram_words, nbigram_words))\n",
      "for u, v in bigrams:\n",
      "    i = bigram_index_map[u]\n",
      "    j = bigram_index_map[v]\n",
      "    joint_prop = bigram_counts[(u,v)] / bigram_sum_counts\n",
      "    marginals_prod_prob = (word_counts[u] / sum_counts) * (word_counts[v] / sum_counts)\n",
      "    S[i,j] = np.log(joint_prop / marginals_prod_prob)\n",
      "print S.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(843, 843)\n"
       ]
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count = 0\n",
      "for row in range(268):\n",
      "    for col in range(268): \n",
      "        if S[row,col] < 0: count += 1\n",
      "print count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n"
       ]
      }
     ],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "u, v = (u'auto', u'workers')\n",
      "i = bigram_index_map[u]\n",
      "j = bigram_index_map[v]\n",
      "print bigram_counts[(u,v)]\n",
      "print S[i,j]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6\n",
        "4.41485375187\n"
       ]
      }
     ],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nrow = len(context_corpus)\n",
      "ncol = nbigram_words\n",
      "print nrow, ncol\n",
      "S_col_average = S.mean(axis=0)\n",
      "print S_col_average[0,10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "197 843\n",
        "0.0159999993928\n"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#X = lil_matrix((nrow,ncol))\n",
      "data = np.zeros((nrow,ncol))\n",
      "position = 0\n",
      "for doc in context_corpus.documents: \n",
      "    for token in doc.tokens:\n",
      "        if token in bigram_index_map:\n",
      "            i = bigram_index_map[token]\n",
      "            data[position, i] = S_col_average[0,i]\n",
      "    position += 1\n",
      "print data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(197, 843)\n"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsa = TruncatedSVD(components)\n",
      "Y = lsa.fit_transform(data)\n",
      "Y = Normalizer(copy=False).fit_transform(Y)\n",
      "print Y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(197, 80)\n"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savetxt(\"/tmp/Y.csv\", Y, delimiter=\",\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
      "from sklearn import metrics\n",
      "nclusters = 35"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kmx = KMeans(n_clusters=nclusters, init='k-means++', max_iter=100, n_init=1,verbose=True)\n",
      "kmy = KMeans(n_clusters=nclusters, init='k-means++', max_iter=100, n_init=1,verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kmx.fit(X)\n",
      "kmy.fit(Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialization complete\n",
        "Iteration  0, inertia 105.920\n",
        "Iteration  1, inertia 93.210\n",
        "Iteration  2, inertia 92.397\n",
        "Iteration  3, inertia 92.201\n",
        "Converged at iteration 3\n",
        "Initialization complete\n",
        "Iteration  0, inertia 24.047\n",
        "Iteration  1, inertia 16.231\n",
        "Iteration  2, inertia 16.063\n",
        "Iteration  3, inertia 16.012\n",
        "Converged at iteration 3\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 194,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, kmx.labels_)) \n",
      "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, kmx.labels_))\n",
      "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, kmx.labels_))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Homogeneity: 0.435\n",
        "Completeness: 0.383\n",
        "V-measure: 0.407\n"
       ]
      }
     ],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, kmy.labels_)) \n",
      "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, kmy.labels_))\n",
      "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, kmy.labels_))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Homogeneity: 0.629\n",
        "Completeness: 0.448\n",
        "V-measure: 0.524\n"
       ]
      }
     ],
     "prompt_number": 196
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "js_corpus = cb.LabeledCorpus(path, \"John Smith Corpus\")\n",
      "js_corpus.initialize_dictionary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def kmeans_test(tcorpus, ntopics, nclusters, XX=[]):\n",
      "    print \"ntopics:\", ntopics\n",
      "    lda = models.ldamodel.LdaModel(tcorpus, id2word=tcorpus.dictionary, num_topics=num_topics, passes=12)\n",
      "    tcorpus_lda = lda[tcorpus]\n",
      "    ncol = num_topics\n",
      "    if len(XX) > 0: \n",
      "        nextra = XX.shape[1]\n",
      "        ncol += nextra\n",
      "    data = np.zeros((nrow,ncol))\n",
      "    position = 0\n",
      "    for doc in tcorpus_lda:\n",
      "        for topic, weight in doc: data[position, topic] = weight\n",
      "        position += 1\n",
      "    if len(XX) > 0: \n",
      "        for i in range(nrow):\n",
      "            for j in range(nextra):\n",
      "                data[i,num_topics+j] = XX[i,j]\n",
      "    print \"shape:\", data.shape\n",
      "    np.savetxt(\"/tmp/Z-%d.csv\" % ntopics, data, delimiter=\",\")\n",
      "    km = KMeans(n_clusters=nclusters, init='k-means++', max_iter=100, n_init=1,verbose=True)    \n",
      "    km.fit(data)\n",
      "    print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_)) \n",
      "    print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
      "    print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_topics = 12\n",
      "nclusters = 35\n",
      "kmeans_test(js_corpus, num_topics, nclusters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ntopics: 12\n",
        "shape:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (197, 12)\n",
        "Initialization complete\n",
        "Iteration  0, inertia 3.689\n",
        "Iteration  1, inertia 2.505\n",
        "Iteration  2, inertia 2.503\n",
        "Converged at iteration 2\n",
        "Homogeneity: 0.774\n",
        "Completeness: 0.533\n",
        "V-measure: 0.631\n"
       ]
      }
     ],
     "prompt_number": 204
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"ntopics:\", num_topics\n",
      "lda = models.ldamodel.LdaModel(js_corpus, id2word=js_corpus.dictionary, num_topics=num_topics, passes=12)\n",
      "tcorpus_lda = lda[js_corpus]\n",
      "ncol = num_topics\n",
      "data = np.zeros((nrow,ncol))\n",
      "position = 0\n",
      "for doc in tcorpus_lda:\n",
      "    for topic, weight in doc: data[position, topic] = weight\n",
      "    position += 1\n",
      "print \"shape:\", data.shape\n",
      "np.savetxt(\"/tmp/Z-%d.csv\" % num_topics, data, delimiter=\",\")\n",
      "km = KMeans(n_clusters=nclusters, init='k-means++', max_iter=200, n_init=1,verbose=True)    \n",
      "km.fit(data)\n",
      "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_)) \n",
      "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
      "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ntopics: 12\n",
        "shape:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (197, 12)\n",
        "Initialization complete\n",
        "Iteration  0, inertia 2.971\n",
        "Iteration  1, inertia 2.225\n",
        "Iteration  2, inertia 2.136\n",
        "Converged at iteration 2\n",
        "Homogeneity: 0.802\n",
        "Completeness: 0.537\n",
        "V-measure: 0.643\n"
       ]
      }
     ],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "position = 0\n",
      "infos = []\n",
      "for doc in js_corpus_lda:\n",
      "    info = [(topic, weight) for topic, weight in doc]\n",
      "    info = sorted(info, key=lambda x: - x[1])\n",
      "    infos.append(info)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from domain import Topic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_data = []\n",
      "for doc in tcorpus_lda:\n",
      "    doc_topic_data = []\n",
      "    for key, weight in doc:\n",
      "        topic = Topic(key, lda)\n",
      "        doc_topic_data.append((weight, topic))\n",
      "    topic_data.append(doc_topic_data)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_data = []\n",
      "for position in range(nrow):\n",
      "    feature_data.append( (position, int(labels[position]), km.labels_[position], topic_data[position]) )\n",
      "feature_data = sorted(feature_data, key=lambda x: x[2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 224
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs\n",
      "fp = codecs.open(\"/tmp/topic-feature-summary.tsv\", 'w', 'utf-8')\n",
      "fp.write(\"Cluster\\tLabel\\tTopic Features\\n\")\n",
      "for record in feature_data:\n",
      "    doc_topic_data = record[3]\n",
      "    doc_topic_data = sorted(doc_topic_data, key=lambda x: -x[0])\n",
      "    description = \"; \".join(\"%0.2f:%s\" % (weight, topic) for weight, topic in doc_topic_data)\n",
      "    fp.write(\"%d\\t%d\\t%s\\n\" % (record[2], record[1], description))\n",
      "fp.close()  \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = np.zeros((nrow,num_topics))\n",
      "position = 0\n",
      "for doc in js_corpus_lda:\n",
      "    for topic, weight in doc: data[position, topic] = weight\n",
      "    position += 1\n",
      "print data.shape\n",
      "kmy.fit(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(197, 50)\n",
        "Initialization complete\n",
        "Iteration  0, inertia 25.176\n",
        "Iteration  1, inertia 17.205\n",
        "Iteration  2, inertia 17.004\n",
        "Iteration  3, inertia 16.891\n",
        "Converged at iteration 3\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 75,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, kmy.labels_)) \n",
      "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, kmy.labels_))\n",
      "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, kmy.labels_))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Homogeneity: 0.754\n",
        "Completeness: 0.501\n",
        "V-measure: 0.602\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}