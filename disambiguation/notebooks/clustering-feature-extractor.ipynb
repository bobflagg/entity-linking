{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd '/home/disambiguation/entity-linking/disambiguation/src/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/CERT/rflagg/disambiguation/entity-linking/disambiguation/src\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs\n",
      "import ConfigParser\n",
      "from data.domain import SUBTYPES\n",
      "import json as simplejson\n",
      "import numpy as np\n",
      "import optparse\n",
      "import os\n",
      "from scipy.sparse import csc_matrix, lil_matrix\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "just to make a change..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "home = '/home/disambiguation/'\n",
      "group = 'js'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_coreference_data(home, group, update=False):\n",
      "  start = time.time()\n",
      "  path = '%s/output/entity/%s/coreference-data.txt' % (home, group)\n",
      "  fp = codecs.open(path, 'r', 'UTF-8')\n",
      "  data = simplejson.load(fp)\n",
      "  fp.close()\n",
      "  nrow = data[\"next-doc-index\"]\n",
      "  ncol = data[\"next-sf-index\"]  \n",
      "  path = '%s/output/entity/fof-sparse.npz' % home\n",
      "  if update or not os.path.exists(path):\n",
      "    print \"Updating first-order features...\"\n",
      "    S = lil_matrix((nrow, ncol))\n",
      "    for doc_id, doc_index in data['doc-index-map'].iteritems():\n",
      "      for sf_index in data['doc-sfs'][doc_id]: S[doc_index, sf_index] = 1.0\n",
      "    S = S.tocsc()\n",
      "    sums = S.sum(axis=0)\n",
      "    np.savez(path, S.data, S.indices, S.indptr, sums)\n",
      "  else: print \"Loading coreference data...\"  \n",
      "  npzfile = np.load(path)\n",
      "  S = csc_matrix((npzfile['arr_0'], npzfile['arr_1'], npzfile['arr_2']), shape=(nrow, ncol))\n",
      "  sums = npzfile['arr_3']\n",
      "  finish = time.time()\n",
      "  print '\\ttook %0.3f s' % (finish-start)\n",
      "  return data, S, sums"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sf_data, S, sums = get_coreference_data(home, group, update=False)\n",
      "sf_map = {value:key for key, value in sf_data['sf-index-map'].iteritems()}\n",
      "doc_map = {value:key for key, value in sf_data['doc-index-map'].iteritems()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading coreference data...\n",
        "\ttook 0.025 s\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def show_coreference_info(doc_index):\n",
      "    results = {}\n",
      "    for key, value in [sf_map[i].split('::') for i in sf_data['doc-sfs'][doc_map[doc_index]]]:\n",
      "        if not key in results: results[key] = set()\n",
      "        results[key].add(value)\n",
      "    keys = results.keys()\n",
      "    keys.sort()\n",
      "    print doc_map[doc_index]\n",
      "    for key in keys:\n",
      "        values = sort(list(results[key]))\n",
      "        print \"\\t%s: %s\" % (key, \"; \".join(values))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show_coreference_info(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "js-28::970501-453_UEM\n",
        "\tCOMPANY: british broadcasting corp.; european union; itn\n",
        "\tGEO: britain; europe; london; u.k.\n",
        "\tLOCATION: updates\n",
        "\tORGANIZATION: bloomberg britain's labour party; conservative party; conservatives; european union; house of commons; labour; labour government; mori for independent television news; parliament\n",
        "\tPERSON: blair; john major; margaret thatcher; paddy ashdown; thatcher; tony blair\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def doc_index(sf_data, doc):\n",
      "    return sf_data['doc-index-map'][doc]\n",
      "\n",
      "def sf_index(sf_data, sf):\n",
      "    return sf_data['sf-index-map'][sf]\n",
      "\n",
      "def get_docs(sf_data, i):\n",
      "    sf = sf_map[i]\n",
      "    return sf_data['sf-docs'][sf]\n",
      "\n",
      "def get_sfs(sf_data, i):\n",
      "    doc = doc_map[i]\n",
      "    return sf_data['doc-sfs'][doc]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def llr(sf_data, sums, i1, i2):\n",
      "    #i1 = sf_index(sf_data, sf1)\n",
      "    #i2 = sf_index(sf_data, sf2)\n",
      "    # compute actuaL cell frequencies\n",
      "    # - outer cells\n",
      "    ndd = float(sf_data['next-doc-index'])\n",
      "    npd = float(sums[0,i1])\n",
      "    ndp = float(sums[0,i2])\n",
      "    nnd = ndd - npd \n",
      "    ndn = ndd - ndp\n",
      "    # - inner cells\n",
      "    docs = [i for i in get_docs(sf_data, i1) if i in get_docs(sf_data, i2)]\n",
      "    npp = float(len(docs))\n",
      "    npn = npd - npp\n",
      "    nnp = ndp - npp\n",
      "    nnn = nnd - nnp\n",
      "    # compute (randomly) predicted cell frequencies\n",
      "    enn = nnd * ndn / ndd\n",
      "    enp = nnd * ndp / ndd\n",
      "    epn = npd * ndn / ndd\n",
      "    epp = npd * ndp / ndd\n",
      "    # compute log-likelihood ratio\n",
      "    result = 0.0\n",
      "    if nnn > 0: result += nnn * np.log(nnn / enn)\n",
      "    if nnp > 0: result += nnp * np.log(nnp / enp)\n",
      "    if npn > 0: result += npn * np.log(npn / epn)\n",
      "    if npp > 0: result += npp * np.log(npp / epp)\n",
      "    return 2.0 * result\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nrow2 = ncol2 = sf_data[\"next-sf-index\"]\n",
      "S2 = lil_matrix((nrow2, ncol2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.time()\n",
      "for i in range(nrow2):\n",
      "    for j in get_docs(sf_data, i):\n",
      "        for k in get_sfs(sf_data, j):\n",
      "            if S2[i,k] > 0: continue\n",
      "            else:\n",
      "                ratio = llr(sf_data, sums, i, k)\n",
      "                if ratio > 3.841: \n",
      "                    S2[i,k] = ratio\n",
      "                    S2[k,i] = ratio\n",
      "finish = time.time()\n",
      "print '\\ttook %0.3f s' % (finish-start)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttook 8.621 s\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.time()\n",
      "nrow = sf_data[\"next-doc-index\"]\n",
      "ncol = sf_data[\"next-sf-index\"]  \n",
      "X = lil_matrix((nrow, ncol))\n",
      "for i in range(nrow):\n",
      "    indices = get_sfs(sf_data, i)\n",
      "    X[i,:] = S2[indices,:].sum(axis=0) / len(indices)\n",
      "finish = time.time()\n",
      "print '\\ttook %0.3f s' % (finish-start)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttook 55.655 s\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn import metrics\n",
      "from sklearn.preprocessing import Normalizer\n",
      "nclusters = 35\n",
      "ncomponents = 58"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate_kmeans(data, nclusters=nclusters, ncomponents=ncomponents):\n",
      "    lsa = TruncatedSVD(ncomponents)\n",
      "    Y = lsa.fit_transform(data)\n",
      "    Y = Normalizer(copy=False).fit_transform(Y)\n",
      "    km = KMeans(n_clusters=nclusters, init='k-means++', max_iter=100, n_init=1,verbose=True)\n",
      "    km.fit(Y)\n",
      "    np.savetxt(\"/tmp/data-%d.csv\" % ncomponents, Y, delimiter=\",\")\n",
      "    f = open(\"/tmp/labels.csv\", 'w')\n",
      "    for label in labels: f.write(\"%s\\n\" % label)\n",
      "    f.close()\n",
      "    print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_)) \n",
      "    print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
      "    print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
      "    return km"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(X, nclusters=35, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialization complete\n",
        "Iteration  0, inertia 68.262\n",
        "Iteration  1, inertia 46.252\n",
        "Iteration  2, inertia 45.963\n",
        "Iteration  3, inertia 45.886\n",
        "Iteration  4, inertia 45.855\n",
        "Converged at iteration 4\n",
        "Homogeneity: 0.838\n",
        "Completeness: 0.554\n",
        "V-measure: 0.667\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(S)\n",
      "evaluate_kmeans(X)\n",
      "evaluate_kmeans(Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialization complete\n",
        "Iteration  0, inertia 4624.000\n",
        "Iteration  1, inertia 3776.167\n",
        "Converged at iteration 1\n",
        "Homogeneity: 0.375\n",
        "Completeness: 0.402\n",
        "V-measure: 0.388\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 580705.204\n",
        "Iteration  1, inertia 409590.612"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  2, inertia 408134.827\n",
        "Converged at iteration 2\n",
        "Homogeneity: 0.611\n",
        "Completeness: 0.447\n",
        "V-measure: 0.516\n",
        "Initialization complete\n",
        "Iteration  0, inertia 101.562\n",
        "Iteration  1, inertia 67.670\n",
        "Iteration  2, inertia 66.250\n",
        "Iteration  3, inertia 65.561"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  4, inertia 65.191\n",
        "Iteration  5, inertia 65.158\n",
        "Converged at iteration 5\n",
        "Homogeneity: 0.826\n",
        "Completeness: 0.545\n",
        "V-measure: 0.657\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "km1.fit(S)\n",
      "km2.fit(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialization complete\n",
        "Iteration  0, inertia 4977.000\n",
        "Iteration  1, inertia 3860.653\n",
        "Iteration  2, inertia 3839.689\n",
        "Iteration  3, inertia 3838.463\n",
        "Iteration  4, inertia 3837.906\n",
        "Converged at iteration 4\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 588649.046\n",
        "Iteration  1, inertia 388515.383"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  2, inertia 385201.257\n",
        "Converged at iteration 2\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km1.labels_)) \n",
      "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km1.labels_))\n",
      "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km1.labels_))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Homogeneity: 0.460\n",
        "Completeness: 0.406\n",
        "V-measure: 0.432\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km2.labels_)) \n",
      "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km2.labels_))\n",
      "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km2.labels_))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Homogeneity: 0.665\n",
        "Completeness: 0.468\n",
        "V-measure: 0.550\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nrow = sf_data[\"next-doc-index\"]\n",
      "ncol = sf_data[\"next-sf-index\"]  \n",
      "labels = range(nrow)\n",
      "for key, value in sf_data['doc-index-map'].iteritems():\n",
      "    labels[value] = key.split('::')[0].split('-')[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsa = TruncatedSVD(ncomponents)\n",
      "Y = lsa.fit_transform(X)\n",
      "Y = Normalizer(copy=False).fit_transform(Y)\n",
      "print Y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(189, 100)\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}