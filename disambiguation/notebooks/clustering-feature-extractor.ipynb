{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd '/home/disambiguation/entity-linking/disambiguation/src/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/CERT/rflagg/disambiguation/entity-linking/disambiguation/src\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs\n",
      "import ConfigParser\n",
      "from data.domain import SUBTYPES\n",
      "import json as simplejson\n",
      "import numpy as np\n",
      "import optparse\n",
      "import os\n",
      "from scipy.sparse import csc_matrix, hstack, lil_matrix\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "home = '/home/disambiguation/'\n",
      "group = 'js'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_coreference_data(home, group, update=False):\n",
      "  start = time.time()\n",
      "  path = '%s/output/entity/%s/coreference-data.txt' % (home, group)\n",
      "  fp = codecs.open(path, 'r', 'UTF-8')\n",
      "  data = simplejson.load(fp)\n",
      "  fp.close()\n",
      "  nrow = data[\"next-doc-index\"]\n",
      "  ncol = data[\"next-sf-index\"]  \n",
      "  path = '%s/output/entity/fof-sparse.npz' % home\n",
      "  if update or not os.path.exists(path):\n",
      "    print \"Updating first-order features...\"\n",
      "    S = lil_matrix((nrow, ncol))\n",
      "    for doc_id, doc_index in data['doc-index-map'].iteritems():\n",
      "      for sf_index in data['doc-sfs'][doc_id]: S[doc_index, sf_index] = 1.0\n",
      "    S = S.tocsc()\n",
      "    sums = S.sum(axis=0)\n",
      "    np.savez(path, S.data, S.indices, S.indptr, sums)\n",
      "  else: print \"Loading coreference data...\"  \n",
      "  npzfile = np.load(path)\n",
      "  S = csc_matrix((npzfile['arr_0'], npzfile['arr_1'], npzfile['arr_2']), shape=(nrow, ncol))\n",
      "  sums = npzfile['arr_3']\n",
      "  finish = time.time()\n",
      "  print '\\ttook %0.3f s' % (finish-start)\n",
      "  return data, S, sums"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sf_data, S, sums = get_coreference_data(home, group, update=False)\n",
      "sf_map = {value:key for key, value in sf_data['sf-index-map'].iteritems()}\n",
      "doc_map = {value:key for key, value in sf_data['doc-index-map'].iteritems()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading coreference data...\n",
        "\ttook 0.032 s\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nrow = sf_data[\"next-doc-index\"]\n",
      "ncol = sf_data[\"next-sf-index\"]  \n",
      "info = {}\n",
      "index_map = {}\n",
      "labels = range(nrow)\n",
      "for key, value in sf_data['doc-index-map'].iteritems():\n",
      "    folder, the_rest = key.split('::')\n",
      "    identifier = the_rest.split()[0].split('-')[-1][:-4]\n",
      "    index = the_rest.split()[-1]\n",
      "    label = folder.split('-')[-1]\n",
      "    labels[value] = label\n",
      "    tag = \"%s-%s\" % (label,identifier)\n",
      "    info[value] = (folder, label, identifier, tag, key, value)\n",
      "    index_map[tag] = value\n",
      "f = open(\"/home/disambiguation/data/info.csv\", 'w')\n",
      "for folder, label, identifier, tag, key, value in info.values(): \n",
      "    f.write(\"%s,%s,%s,%s,%s,%d\\n\" % (folder, label, identifier, tag, key, value))\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def show_coreference_info(doc_index):\n",
      "    results = {}\n",
      "    for key, value in [sf_map[i].split('::') for i in sf_data['doc-sfs'][doc_map[doc_index]]]:\n",
      "        if not key in results: results[key] = set()\n",
      "        results[key].add(value)\n",
      "    keys = results.keys()\n",
      "    keys.sort()\n",
      "    print doc_map[doc_index]\n",
      "    for key in keys:\n",
      "        values = sort(list(results[key]))\n",
      "        print \"\\t%s: %s\" % (key, \"; \".join(values))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for key in [key for key in index_map.keys() if key.startswith('1-')]:\n",
      "    show_coreference_info(index_map[key])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "js-1::970630-99_UEM\n",
        "\tCOMPANY: bloomberg; bloomberg scottish & newcastle plc; carlsberg; foster's brewing group ltd.; nikko international plc.; s&n; scottish & newcastle; whitbread plc\n",
        "\tGEO: beck's; britain; carlsberg; center parcs; chef & brewer; europe; kronenbourg; london; rat & parrot; tetley; u.k.\n",
        "\tORGANIZATION: bass; bass plc; carlsberg tetley; newcastle brown ale; rat & parrot and chef & brewer chains; s&n; scottish & newcastle\n",
        "\tPERSON: beck; dermott carr; finance director derek wilkinson; foster; pontin; wilkinson\n",
        "js-1::961106-964_UEM\n",
        "\tCOMPANY: apple computer; bbdo; collett dickinson pearce & partners; ggt group; interpublic group of cos.; levi's; mtv; nyt; omnicom; omnicom group; saatchi & saatchi for british airways; volvo\n",
        "\tGEO: america; atlantic; britain; collett; dickinson; england; hamlet; hollywood; london; manhattan; museum of modern art; new york; old west; pens; uk; united kingdom; united states; yosemite national park\n",
        "\tLOCATION: hardy\n",
        "\tORGANIZATION: abbott mead vickers bbdo; bartle bogle hegarty; boase massimi pollitt; cordiant plc; ggt group for holsten pils; laurel; parker pens; saatchi & saatchi; tbwa chiat/day\n",
        "\tPERSON: adrian lyne; alan parker; ansel adams; barry day; bigg; calvin klein; cleese; collett dickinson pearce; day; george bernard shaw; hugh hudson; john cheever; john cleese; laurence kardish; levi; like kardish; louise; monty python; parker; penelope keith; peter bigg; richard loncraine; ridley scott; tony kaye\n",
        "\tSPORTS: tbwa\n",
        "js-1::970630-222_UEM\n",
        "\tCOMPANY: bloomberg; bloomberg scottish & newcastle plc; carlsberg; foster's brewing group ltd.; nikko international plc.; s&n; scottish & newcastle; whitbread plc\n",
        "\tGEO: beck's; britain; carlsberg; center parcs; chef & brewer; europe; kronenbourg; london; rat & parrot; tetley; u.k.\n",
        "\tORGANIZATION: bass; bass plc; carlsberg tetley; newcastle brown ale; rat & parrot and chef & brewer chains; s&n; scottish & newcastle\n",
        "\tPERSON: beck; dermott carr; finance director derek wilkinson; foster; pontin; wilkinson\n",
        "js-1::960701-76_UEM\n",
        "\tCOMPANY: bloomberg scottish & newcastle; charterhouse tilney; charterhouse tilney securities; foster's brewing group ltd.; goldman sachs; newcastle brown ale; s&n\n",
        "\tGEO: britain; charterhouse; chef & brewer; edinburgh; france; german village; london; rat & parrot; scottish & newcastle; theakston; tilney; u.k.\n",
        "\tLOCATION: benelux; benelux region\n",
        "\tORGANIZATION: centre parcs fell; chef & brewer and homespreads chains; parson of charterhouse tilney; rewrites; theakston best bitter\n",
        "\tPERSON: alick rankin; colin davies; foster; holsten; miller pilsner; newcastle brown; nigel parson; pontin\n",
        "js-1::960701-288_UEM\n",
        "\tCOMPANY: bloomberg scottish & newcastle; charterhouse tilney; charterhouse tilney securities; foster's brewing group ltd.; goldman sachs; newcastle brown ale; s&n\n",
        "\tGEO: britain; charterhouse; chef & brewer; edinburgh; france; german village; london; rat & parrot; scottish & newcastle; tilney; u.k.; waverley\n",
        "\tLOCATION: benelux; benelux region\n",
        "\tORGANIZATION: adds detail; centre parcs fell; chef & brewer; chef & brewer and homespreads chains; chef & brewer outlets; parson of charterhouse tilney; theakston best bitter; waverley vintners\n",
        "\tPERSON: alick rankin; brian stewart; colin davies; foster; holsten; miller pilsner; newcastle brown; nigel parson; pontin; stewart\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def doc_index(sf_data, doc):\n",
      "    return sf_data['doc-index-map'][doc]\n",
      "\n",
      "def sf_index(sf_data, sf):\n",
      "    return sf_data['sf-index-map'][sf]\n",
      "\n",
      "def get_docs(sf_data, i):\n",
      "    sf = sf_map[i]\n",
      "    return sf_data['sf-docs'][sf]\n",
      "\n",
      "def get_sfs(sf_data, i):\n",
      "    doc = doc_map[i]\n",
      "    return sf_data['doc-sfs'][doc]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def llr(sf_data, sums, i1, i2):\n",
      "    #i1 = sf_index(sf_data, sf1)\n",
      "    #i2 = sf_index(sf_data, sf2)\n",
      "    # compute actuaL cell frequencies\n",
      "    # - outer cells\n",
      "    ndd = float(sf_data['next-doc-index'])\n",
      "    npd = float(sums[0,i1])\n",
      "    ndp = float(sums[0,i2])\n",
      "    nnd = ndd - npd \n",
      "    ndn = ndd - ndp\n",
      "    # - inner cells\n",
      "    docs = [i for i in get_docs(sf_data, i1) if i in get_docs(sf_data, i2)]\n",
      "    npp = float(len(docs))\n",
      "    npn = npd - npp\n",
      "    nnp = ndp - npp\n",
      "    nnn = nnd - nnp\n",
      "    # compute (randomly) predicted cell frequencies\n",
      "    enn = nnd * ndn / ndd\n",
      "    enp = nnd * ndp / ndd\n",
      "    epn = npd * ndn / ndd\n",
      "    epp = npd * ndp / ndd\n",
      "    # compute log-likelihood ratio\n",
      "    result = 0.0\n",
      "    if nnn > 0: result += nnn * np.log(nnn / enn)\n",
      "    if nnp > 0: result += nnp * np.log(nnp / enp)\n",
      "    if npn > 0: result += npn * np.log(npn / epn)\n",
      "    if npp > 0: result += npp * np.log(npp / epp)\n",
      "    return 2.0 * result\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chi_square_cut_off = 3.841\n",
      "#chi_square_cut_off = 6.635\n",
      "#chi_square_cut_off = 0.01\n",
      "nrow2 = ncol2 = sf_data[\"next-sf-index\"]\n",
      "S2 = lil_matrix((nrow2, ncol2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.time()\n",
      "for i in range(nrow2):\n",
      "    for j in get_docs(sf_data, i):\n",
      "        for k in get_sfs(sf_data, j):\n",
      "            if S2[i,k] > 0: continue\n",
      "            else:\n",
      "                ratio = llr(sf_data, sums, i, k)\n",
      "                if ratio > chi_square_cut_off: \n",
      "                    S2[i,k] = ratio\n",
      "                    S2[k,i] = ratio\n",
      "finish = time.time()\n",
      "print '\\ttook %0.3f s' % (finish-start)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttook 8.478 s\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.time()\n",
      "nrow = sf_data[\"next-doc-index\"]\n",
      "ncol = sf_data[\"next-sf-index\"]  \n",
      "X = lil_matrix((nrow, ncol))\n",
      "for i in range(nrow):\n",
      "    indices = get_sfs(sf_data, i)\n",
      "    X[i,:] = S2[indices,:].sum(axis=0) / len(indices)\n",
      "finish = time.time()\n",
      "print '\\ttook %0.3f s' % (finish-start)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttook 55.383 s\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn import metrics\n",
      "from sklearn.preprocessing import Normalizer\n",
      "nclusters = 35\n",
      "ncomponents = 58"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate_kmeans(data, nclusters=nclusters, ncomponents=ncomponents):\n",
      "    num_rows, num_cols = data.shape\n",
      "    print num_rows, num_cols\n",
      "    if num_cols > ncomponents:\n",
      "        lsa = TruncatedSVD(ncomponents)\n",
      "        Y = lsa.fit_transform(data)\n",
      "        Y = Normalizer(copy=False).fit_transform(Y)\n",
      "    else: \n",
      "        Y = data.todense()\n",
      "        ncomponents = num_cols\n",
      "    km = KMeans(n_clusters=nclusters, init='k-means++', max_iter=100, n_init=1,verbose=True)\n",
      "    km.fit(Y)\n",
      "    np.savetxt(\"/home/disambiguation/data/data-%d.csv\" % ncomponents, Y, delimiter=\",\")\n",
      "    print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_)) \n",
      "    print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
      "    print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
      "    return km"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(S, nclusters=35, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 3727\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 98.755\n",
        "Iteration  1, inertia 66.129\n",
        "Iteration  2, inertia 66.017\n",
        "Converged at iteration 2\n",
        "Homogeneity: 0.832\n",
        "Completeness: 0.525\n",
        "V-measure: 0.643\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(X, nclusters=35, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 3727\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 71.383\n",
        "Iteration  1, inertia 46.353\n",
        "Iteration  2, inertia 46.114\n",
        "Iteration  3, inertia 46.084\n",
        "Converged at iteration 3\n",
        "Homogeneity: 0.866\n",
        "Completeness: 0.555\n",
        "V-measure: 0.677\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(hstack([S,X]), nclusters=35, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 7454\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 72.325\n",
        "Iteration  1, inertia 49.333\n",
        "Iteration  2, inertia 49.204\n",
        "Converged at iteration 2\n",
        "Homogeneity: 0.837\n",
        "Completeness: 0.534\n",
        "V-measure: 0.652\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Investigate Topic Features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_topic_data(home, group, update=False):\n",
      "  start = time.time()\n",
      "  path = '%s/output/entity/%s/topic-data.json' % (home, group)\n",
      "  fp = codecs.open(path, 'r', 'UTF-8')\n",
      "  topic_data = simplejson.load(fp)\n",
      "  fp.close()\n",
      "  ntopics = topic_data[\"number-of-topics\"]  \n",
      "  TS = lil_matrix((nrow, ntopics))\n",
      "  for key, value in topic_data['document_topics'].iteritems():\n",
      "    for doc, topics in value.iteritems():\n",
      "      doc_key = \"%s::%s_UEM\" % (key, doc[:-9])\n",
      "      i = sf_data['doc-index-map'][doc_key]\n",
      "      for t, w, _ in topics: TS[i,t] = w\n",
      "  TS = TS.tocsc()\n",
      "  finish = time.time()\n",
      "  print '\\ttook %0.3f s' % (finish-start)\n",
      "  return topic_data, TS"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_data, TS = get_topic_data(home, group, update=False)\n",
      "print TS.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttook 0.007 s\n",
        "(189, 12)\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sf_data['doc-index-map'][\"js-13::960920-114_UEM\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TS[2,6]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "0.0"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(TS, nclusters=35, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 12\n",
        "Initialization complete\n",
        "Iteration  0, inertia 3.469\n",
        "Iteration  1, inertia 2.391\n",
        "Iteration  2, inertia 2.377\n",
        "Iteration  3, inertia 2.374\n",
        "Converged at iteration 3\n",
        "Homogeneity: 0.666\n",
        "Completeness: 0.469\n",
        "V-measure: 0.550\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(hstack([S,TS]), nclusters=35, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 3739\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 96.271\n",
        "Iteration  1, inertia 65.665\n",
        "Iteration  2, inertia 65.314\n",
        "Iteration  3, inertia 65.008\n",
        "Converged at iteration 3\n",
        "Homogeneity: 0.759\n",
        "Completeness: 0.481\n",
        "V-measure: 0.589\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(hstack([X,TS]), nclusters=35, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 3739\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 72.485\n",
        "Iteration  1, inertia 47.878\n",
        "Iteration  2, inertia 47.622\n",
        "Iteration  3, inertia 47.581\n",
        "Converged at iteration 3\n",
        "Homogeneity: 0.839\n",
        "Completeness: 0.545\n",
        "V-measure: 0.660\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(hstack([S,X,TS]), nclusters=35, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 7466\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 72.098\n",
        "Iteration  1, inertia 48.037\n",
        "Iteration  2, inertia 47.596\n",
        "Iteration  3, inertia 47.510\n",
        "Iteration  4, inertia 47.487\n",
        "Converged at iteration 4\n",
        "Homogeneity: 0.846\n",
        "Completeness: 0.550\n",
        "V-measure: 0.667\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 43
    }
   ],
   "metadata": {}
  }
 ]
}