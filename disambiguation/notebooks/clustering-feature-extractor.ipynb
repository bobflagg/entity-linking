{
 "metadata": {
  "name": "clustering-feature-extractor"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd '/home/disambiguation/entity-linking/disambiguation/src/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/disambiguation/entity-linking/disambiguation/src\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs\n",
      "import ConfigParser\n",
      "from data.domain import SUBTYPES\n",
      "import json as simplejson\n",
      "import numpy as np\n",
      "import optparse\n",
      "import os\n",
      "from scipy.sparse import csc_matrix, hstack, lil_matrix\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "home = '/home/disambiguation/'\n",
      "group = 'js'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_coreference_data(home, group, update=False):\n",
      "  start = time.time()\n",
      "  path = '%s/output/entity/%s/coreference-data.txt' % (home, group)\n",
      "  fp = codecs.open(path, 'r', 'UTF-8')\n",
      "  data = simplejson.load(fp)\n",
      "  fp.close()\n",
      "  nrow = data[\"next-doc-index\"]\n",
      "  ncol = data[\"next-sf-index\"]  \n",
      "  path = '%s/output/entity/fof-sparse.npz' % home\n",
      "  if update or not os.path.exists(path):\n",
      "    print \"Updating first-order features...\"\n",
      "    S = lil_matrix((nrow, ncol))\n",
      "    for doc_id, doc_index in data['doc-index-map'].iteritems():\n",
      "      for sf_index in data['doc-sfs'][doc_id]: S[doc_index, sf_index] = 1.0\n",
      "    S = S.tocsc()\n",
      "    sums = S.sum(axis=0)\n",
      "    np.savez(path, S.data, S.indices, S.indptr, sums)\n",
      "  else: print \"Loading coreference data...\"  \n",
      "  npzfile = np.load(path)\n",
      "  S = csc_matrix((npzfile['arr_0'], npzfile['arr_1'], npzfile['arr_2']), shape=(nrow, ncol))\n",
      "  sums = npzfile['arr_3']\n",
      "  finish = time.time()\n",
      "  print '\\ttook %0.3f s' % (finish-start)\n",
      "  return data, S, sums"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sf_data, S, sums = get_coreference_data(home, group, update=False)\n",
      "sf_map = {value:key for key, value in sf_data['sf-index-map'].iteritems()}\n",
      "doc_map = {value:key for key, value in sf_data['doc-index-map'].iteritems()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Updating first-order features...\n",
        "\ttook 0.945 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nrow = sf_data[\"next-doc-index\"]\n",
      "ncol = sf_data[\"next-sf-index\"]  \n",
      "info = {}\n",
      "index_map = {}\n",
      "labels = range(nrow)\n",
      "for key, value in sf_data['doc-index-map'].iteritems():\n",
      "    folder, the_rest = key.split('::')\n",
      "    identifier = the_rest.split()[0].split('-')[-1][:-4]\n",
      "    index = the_rest.split()[-1]\n",
      "    label = folder.split('-')[-1]\n",
      "    labels[value] = label\n",
      "    tag = \"%s-%s\" % (label,identifier)\n",
      "    info[value] = (folder, label, identifier, tag, key, value)\n",
      "    index_map[tag] = value\n",
      "f = open(\"/home/disambiguation/data/info.csv\", 'w')\n",
      "for folder, label, identifier, tag, key, value in info.values(): \n",
      "    f.write(\"%s,%s,%s,%s,%s,%d\\n\" % (folder, label, identifier, tag, key, value))\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def show_coreference_info(doc_index):\n",
      "    results = {}\n",
      "    for key, value in [sf_map[i].split('::') for i in sf_data['doc-sfs'][doc_map[doc_index]]]:\n",
      "        if not key in results: results[key] = set()\n",
      "        results[key].add(value)\n",
      "    keys = results.keys()\n",
      "    keys.sort()\n",
      "    print doc_map[doc_index]\n",
      "    for key in keys:\n",
      "        values = sort(list(results[key]))\n",
      "        print \"\\t%s: %s\" % (key, \"; \".join(values))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show_coreference_info(index_map[\"28-25\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "js-28::970504-25_UEM\n",
        "\tCOMPANY: bloomberg; european union; trade and industry; treasury\n",
        "\tGEO: britain; europe; exchequer; lancaster; london; northern ireland; scottish parliament; u.k.\n",
        "\tGOVERNMENT: cabinet; house of commons; national health service\n",
        "\tLOCATION: irvine; labour\n",
        "\tORGANIZATION: defense; european commission; house of lords; labour; liberal democrats; national heritage; scottish national party; u.k. labour party; u.k. labour party government; united nations; welsh nationalists\n",
        "\tPERSON: alistair darling he; ann taylor; blair; clare short many; david blunkett; david clark effectively; donald dewar; frank dobson energetic; gavin strang; george robertson; gordon brown may; harriet harman; ivor richard he; jack cunningham; jack straw he; john prescott; margaret beckett; mo mowlam she; robin cook; ron davies; tony blair\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show_coreference_info(index_map[\"28-74\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "js-28::970502-74_UEM\n",
        "\tCOMPANY: baa plc; bloomberg; british telecommunications plc; edinburgh managers plc; ga investments ltd.; old labour\n",
        "\tEDUCATIONAL: fettes college; university of oxford\n",
        "\tGEO: britain; county durham; edinburgh; england; europe; exchequer; heathrow; london; scotland; sedgefield; u.k.; u.s.\n",
        "\tGOVERNMENT: parliament; u.s. democratic party\n",
        "\tLOCATION: london; northeast england; parliament; u.s.\n",
        "\tORGANIZATION: blair scrapped labour; commons; conservative party; labour; labour government; labour party; u.k. labour party\n",
        "\tPERSON: abraham lincoln; andrew milligan; bill clinton; blair; brown; cherie booth; gordon brown; graham campbell; john major; john wilkes booth; labour; lord liverpool; major; neil kinnock; tony blair\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for key in [key for key in index_map.keys() if key.startswith('1-')]:\n",
      "    show_coreference_info(index_map[key])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "js-1::970630-99_UEM\n",
        "\tCOMPANY: bloomberg; bloomberg scottish & newcastle plc; carlsberg; foster's brewing group ltd.; nikko international plc.; s&n; scottish & newcastle; whitbread plc\n",
        "\tGEO: beck's; britain; carlsberg; center parcs; chef & brewer; europe; kronenbourg; london; rat & parrot; tetley; u.k.\n",
        "\tORGANIZATION: bass; bass plc; carlsberg tetley; newcastle brown ale; rat & parrot and chef & brewer chains; s&n; scottish & newcastle\n",
        "\tPERSON: beck; dermott carr; finance director derek wilkinson; foster; pontin; wilkinson\n",
        "js-1::961106-964_UEM\n",
        "\tCOMPANY: apple computer; bbdo; collett dickinson pearce & partners; ggt group; interpublic group of cos.; levi's; mtv; nyt; omnicom; omnicom group; saatchi & saatchi for british airways; volvo\n",
        "\tGEO: america; atlantic; britain; collett; dickinson; england; hamlet; hollywood; london; manhattan; museum of modern art; new york; old west; pens; uk; united kingdom; united states; yosemite national park\n",
        "\tLOCATION: hardy\n",
        "\tORGANIZATION: abbott mead vickers bbdo; bartle bogle hegarty; boase massimi pollitt; cordiant plc; ggt group for holsten pils; laurel; parker pens; saatchi & saatchi; tbwa chiat/day\n",
        "\tPERSON: adrian lyne; alan parker; ansel adams; barry day; bigg; calvin klein; cleese; collett dickinson pearce; day; george bernard shaw; hugh hudson; john cheever; john cleese; laurence kardish; levi; like kardish; louise; monty python; parker; penelope keith; peter bigg; richard loncraine; ridley scott; tony kaye\n",
        "\tSPORTS: tbwa\n",
        "js-1::970630-222_UEM\n",
        "\tCOMPANY: bloomberg; bloomberg scottish & newcastle plc; carlsberg; foster's brewing group ltd.; nikko international plc.; s&n; scottish & newcastle; whitbread plc\n",
        "\tGEO: beck's; britain; carlsberg; center parcs; chef & brewer; europe; kronenbourg; london; rat & parrot; tetley; u.k.\n",
        "\tORGANIZATION: bass; bass plc; carlsberg tetley; newcastle brown ale; rat & parrot and chef & brewer chains; s&n; scottish & newcastle\n",
        "\tPERSON: beck; dermott carr; finance director derek wilkinson; foster; pontin; wilkinson\n",
        "js-1::960701-76_UEM\n",
        "\tCOMPANY: bloomberg scottish & newcastle; charterhouse tilney; charterhouse tilney securities; foster's brewing group ltd.; goldman sachs; newcastle brown ale; s&n\n",
        "\tGEO: britain; charterhouse; chef & brewer; edinburgh; france; german village; london; rat & parrot; scottish & newcastle; theakston; tilney; u.k.\n",
        "\tLOCATION: benelux; benelux region\n",
        "\tORGANIZATION: centre parcs fell; chef & brewer and homespreads chains; parson of charterhouse tilney; rewrites; theakston best bitter\n",
        "\tPERSON: alick rankin; colin davies; foster; holsten; miller pilsner; newcastle brown; nigel parson; pontin\n",
        "js-1::960701-288_UEM\n",
        "\tCOMPANY: bloomberg scottish & newcastle; charterhouse tilney; charterhouse tilney securities; foster's brewing group ltd.; goldman sachs; newcastle brown ale; s&n\n",
        "\tGEO: britain; charterhouse; chef & brewer; edinburgh; france; german village; london; rat & parrot; scottish & newcastle; tilney; u.k.; waverley\n",
        "\tLOCATION: benelux; benelux region\n",
        "\tORGANIZATION: adds detail; centre parcs fell; chef & brewer; chef & brewer and homespreads chains; chef & brewer outlets; parson of charterhouse tilney; theakston best bitter; waverley vintners\n",
        "\tPERSON: alick rankin; brian stewart; colin davies; foster; holsten; miller pilsner; newcastle brown; nigel parson; pontin; stewart\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show_coreference_info(index_map[\"13-114\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "js-13::960920-114_UEM\n",
        "\tCOMPANY: new york times news service; warner\n",
        "\tGEO: chicago; jericho; kelly's; mexico; small texas\n",
        "\tLOCATION: atlanta; chicago south\n",
        "\tPERSON: akira kurosawa; bruce dern; bruce willis; cagney; christopher walken; david patrick kelly; eleanor ringel; henry fonda; john wayne; kelly; ned eisenberg; sergio leone; walter hill; willis\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show_coreference_info(index_map[\"13-533\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "js-13::960919-533_UEM\n",
        "\tGEO: felina; jericho; wanda; west texas\n",
        "\tLOCATION: hill; karina lombard; new line cinema; wild west\n",
        "\tORGANIZATION: hell\n",
        "\tPERSON: akira kurosawa; alexandra powers; arthur sarkissian; bill; bruce dern; bruce willis; christopher walken; dashiell hammett; david patrick kelly; doyle; ed galt; freeman davies; gary wissner; giorgio carmonte; hickey; hill; james m. cain ese; kurosawa; leslie mann; lloyd ahern; lucy kolinski; michael imperioli; mifune; ryuzo kikushima; sam peckinpah; toshiro mifune; walter hill; wanda; willis\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def doc_index(sf_data, doc):\n",
      "    return sf_data['doc-index-map'][doc]\n",
      "\n",
      "def sf_index(sf_data, sf):\n",
      "    return sf_data['sf-index-map'][sf]\n",
      "\n",
      "def get_docs(sf_data, i):\n",
      "    sf = sf_map[i]\n",
      "    return sf_data['sf-docs'][sf]\n",
      "\n",
      "def get_sfs(sf_data, i):\n",
      "    doc = doc_map[i]\n",
      "    return sf_data['doc-sfs'][doc]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def llr(sf_data, sums, i1, i2):\n",
      "    #i1 = sf_index(sf_data, sf1)\n",
      "    #i2 = sf_index(sf_data, sf2)\n",
      "    # compute actuaL cell frequencies\n",
      "    # - outer cells\n",
      "    ndd = float(sf_data['next-doc-index'])\n",
      "    npd = float(sums[0,i1])\n",
      "    ndp = float(sums[0,i2])\n",
      "    nnd = ndd - npd \n",
      "    ndn = ndd - ndp\n",
      "    # - inner cells\n",
      "    docs = [i for i in get_docs(sf_data, i1) if i in get_docs(sf_data, i2)]\n",
      "    npp = float(len(docs))\n",
      "    npn = npd - npp\n",
      "    nnp = ndp - npp\n",
      "    nnn = nnd - nnp\n",
      "    # compute (randomly) predicted cell frequencies\n",
      "    enn = nnd * ndn / ndd\n",
      "    enp = nnd * ndp / ndd\n",
      "    epn = npd * ndn / ndd\n",
      "    epp = npd * ndp / ndd\n",
      "    # compute log-likelihood ratio\n",
      "    result = 0.0\n",
      "    if nnn > 0: result += nnn * np.log(nnn / enn)\n",
      "    if nnp > 0: result += nnp * np.log(nnp / enp)\n",
      "    if npn > 0: result += npn * np.log(npn / epn)\n",
      "    if npp > 0: result += npp * np.log(npp / epp)\n",
      "    return 2.0 * result\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chi_square_cut_off = 3.841\n",
      "chi_square_cut_off = 6.635\n",
      "chi_square_cut_off = 0.01\n",
      "nrow2 = ncol2 = sf_data[\"next-sf-index\"]\n",
      "S2 = lil_matrix((nrow2, ncol2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.time()\n",
      "for i in range(nrow2):\n",
      "    for j in get_docs(sf_data, i):\n",
      "        for k in get_sfs(sf_data, j):\n",
      "            if S2[i,k] > 0: continue\n",
      "            else:\n",
      "                ratio = llr(sf_data, sums, i, k)\n",
      "                if ratio > chi_square_cut_off: \n",
      "                    S2[i,k] = ratio\n",
      "                    S2[k,i] = ratio\n",
      "finish = time.time()\n",
      "print '\\ttook %0.3f s' % (finish-start)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttook 42.984 s\n"
       ]
      }
     ],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.time()\n",
      "nrow = sf_data[\"next-doc-index\"]\n",
      "ncol = sf_data[\"next-sf-index\"]  \n",
      "X = lil_matrix((nrow, ncol))\n",
      "for i in range(nrow):\n",
      "    indices = get_sfs(sf_data, i)\n",
      "    X[i,:] = S2[indices,:].sum(axis=0) / len(indices)\n",
      "finish = time.time()\n",
      "print '\\ttook %0.3f s' % (finish-start)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttook 89.885 s\n"
       ]
      }
     ],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Z = hstack([S,X])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn import metrics\n",
      "from sklearn.preprocessing import Normalizer\n",
      "nclusters = 35\n",
      "ncomponents = 58"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate_kmeans(data, nclusters=nclusters, ncomponents=ncomponents):\n",
      "    num_rows, num_cols = data.shape\n",
      "    print num_rows, num_cols\n",
      "    if num_cols > ncomponents:\n",
      "        lsa = TruncatedSVD(ncomponents)\n",
      "        Y = lsa.fit_transform(data)\n",
      "        Y = Normalizer(copy=False).fit_transform(Y)\n",
      "    else: \n",
      "        Y = data\n",
      "        ncomponents = num_cols\n",
      "    km = KMeans(n_clusters=nclusters, init='k-means++', max_iter=100, n_init=1,verbose=True)\n",
      "    km.fit(Y)\n",
      "    np.savetxt(\"/home/disambiguation/data/data-%d.csv\" % ncomponents, Y, delimiter=\",\")\n",
      "    print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_)) \n",
      "    print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
      "    print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
      "    return km"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(X, nclusters=35, ncomponents=48)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 3727\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 61.793\n",
        "Iteration  1, inertia 41.175\n",
        "Iteration  2, inertia 40.681\n",
        "Iteration  3, inertia 40.470\n",
        "Iteration  4, inertia 40.424\n",
        "Iteration  5, inertia 40.398\n",
        "Converged at iteration 5\n",
        "Homogeneity: 0.842\n",
        "Completeness: 0.549\n",
        "V-measure: 0.665\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 190,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TSZ = hstack([TS,S,X])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(X, nclusters=35, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 3727\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 75.018\n",
        "Iteration  1, inertia 50.900\n",
        "Iteration  2, inertia 49.454\n",
        "Iteration  3, inertia 48.989\n",
        "Iteration  4, inertia 48.556\n",
        "Iteration  5, inertia 48.341\n",
        "Iteration  6, inertia 48.174\n",
        "Converged at iteration 6\n",
        "Homogeneity: 0.816\n",
        "Completeness: 0.536\n",
        "V-measure: 0.647\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 156,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(X, nclusters=35, ncomponents=60)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialization complete\n",
        "Iteration  0, inertia 72.121\n",
        "Iteration  1, inertia 47.991\n",
        "Iteration  2, inertia 47.467\n",
        "Converged at iteration 2\n",
        "Homogeneity: 0.824\n",
        "Completeness: 0.535\n",
        "V-measure: 0.649\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(S, nclusters=35, ncomponents=60)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialization complete\n",
        "Iteration  0, inertia 101.065\n",
        "Iteration  1, inertia 67.285\n",
        "Iteration  2, inertia 66.528\n",
        "Iteration  3, inertia 66.173\n",
        "Iteration  4, inertia 66.052\n",
        "Converged at iteration 4\n",
        "Homogeneity: 0.804\n",
        "Completeness: 0.506\n",
        "V-measure: 0.622\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(Z, nclusters=35, ncomponents=60)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialization complete\n",
        "Iteration  0, inertia 71.526\n",
        "Iteration  1, inertia 49.604\n",
        "Iteration  2, inertia 49.028\n",
        "Converged at iteration 2\n",
        "Homogeneity: 0.855\n",
        "Completeness: 0.573\n",
        "V-measure: 0.686\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Investigate Topic Features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_topic_data(home, group, update=False):\n",
      "  start = time.time()\n",
      "  path = '%s/output/entity/%s/topic-data.json' % (home, group)\n",
      "  fp = codecs.open(path, 'r', 'UTF-8')\n",
      "  topic_data = simplejson.load(fp)\n",
      "  fp.close()\n",
      "  ntopics = topic_data[\"number-of-topics\"]  \n",
      "  TS = lil_matrix((nrow, ntopics))\n",
      "  for key, value in topic_data['document_topics'].iteritems():\n",
      "    for doc, topics in value.iteritems():\n",
      "      doc_key = \"%s::%s_UEM\" % (key, doc[:-9])\n",
      "      i = sf_data['doc-index-map'][doc_key]\n",
      "      for t, w, _ in topics: TS[i,t] = w\n",
      "  TS = TS.tocsc()\n",
      "  finish = time.time()\n",
      "  print '\\ttook %0.3f s' % (finish-start)\n",
      "  return topic_data, TS"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_data, TS = get_topic_data(home, group, update=False)\n",
      "print TS.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttook 0.050 s\n",
        "(189, 12)\n"
       ]
      }
     ],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sf_data['doc-index-map'][\"js-13::960920-114_UEM\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TS[2,77]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "0.31094651038929838"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(TS, nclusters=35, ncomponents=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 12\n",
        "Initialization complete"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "tuple index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-195-992dfba07e0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_kmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnclusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncomponents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-146-e00ddfb17a39>\u001b[0m in \u001b[0;36mevaluate_kmeans\u001b[0;34m(data, nclusters, ncomponents)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mkm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k-means++'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/disambiguation/data/data-%d.csv\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mncomponents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/disambiguation/data/labels.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[1;32m   1008\u001b[0m                 \u001b[0mncol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mncol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0miscomplex_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miscomplexobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 6.110\n",
        "Iteration  1, inertia 4.419\n",
        "Iteration  2, inertia 4.289\n",
        "Converged at iteration 2\n"
       ]
      }
     ],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_rows, num_cols = TS.shape\n",
      "print num_rows, num_cols\n",
      "km = KMeans(n_clusters=nclusters, init='k-means++', max_iter=100, n_init=1,verbose=True)\n",
      "km.fit(TS)\n",
      "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_)) \n",
      "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
      "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 12\n",
        "Initialization complete\n",
        "Iteration  0, inertia 6.150\n",
        "Iteration  1, inertia 4.078\n",
        "Iteration  2, inertia 4.024\n",
        "Iteration  3, inertia 4.021"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Converged at iteration 3\n",
        "Homogeneity: 0.669\n",
        "Completeness: 0.437\n",
        "V-measure: 0.528\n"
       ]
      }
     ],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savetxt(\"/home/disambiguation/data/data-%d.csv\" % ncomponents, TS, delimiter=\",\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "tuple index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-198-5c84d032f6e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/disambiguation/data/data-%d.csv\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mncomponents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[1;32m   1008\u001b[0m                 \u001b[0mncol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mncol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0miscomplex_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miscomplexobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
       ]
      }
     ],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TS.shape[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 199,
       "text": [
        "12"
       ]
      }
     ],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}