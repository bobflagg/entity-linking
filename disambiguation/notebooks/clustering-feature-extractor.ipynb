{
 "metadata": {
  "name": "clustering-feature-extractor"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd '/home/disambiguation/entity-linking/disambiguation/src/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/disambiguation/entity-linking/disambiguation/src\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs\n",
      "import ConfigParser\n",
      "from data.domain import SUBTYPES\n",
      "import json as simplejson\n",
      "import numpy as np\n",
      "import optparse\n",
      "import os\n",
      "from scipy.sparse import csc_matrix, lil_matrix\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "home = '/home/disambiguation/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def first_order_features(home, update=False):\n",
      "  start = time.time()\n",
      "  path = '%s/output/entity/surface-form-data.txt' % home\n",
      "  fp = codecs.open(path, 'r', 'UTF-8')\n",
      "  data = simplejson.load(fp)\n",
      "  fp.close()\n",
      "  nrow = data[\"next-doc-index\"]\n",
      "  ncol = data[\"next-sf-index\"]  \n",
      "  path = '%s/output/entity/fof-sparse.npz' % home\n",
      "  if update or not os.path.exists(path):\n",
      "    print \"Updating first-order features...\"\n",
      "    S = lil_matrix((nrow, ncol))\n",
      "    for doc_id, doc_index in data['doc-index-map'].iteritems():\n",
      "      for sf_index in data['doc-sfs'][doc_id]: S[doc_index, sf_index] = 1.0\n",
      "    S = S.tocsc()\n",
      "    sums = S.sum(axis=0)\n",
      "    np.savez(path, S.data, S.indices, S.indptr, sums)\n",
      "  else: print \"Loading first-order features...\"  \n",
      "  npzfile = np.load(path)\n",
      "  S = csc_matrix((npzfile['arr_0'], npzfile['arr_1'], npzfile['arr_2']), shape=(nrow, ncol))\n",
      "  sums = npzfile['arr_3']\n",
      "  finish = time.time()\n",
      "  print '\\ttook %0.3f s' % (finish-start)\n",
      "  return data, S, sums"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sf_data, S, sums = first_order_features(home, update=False)\n",
      "sf_map = {value:key for key, value in sf_data['sf-index-map'].iteritems()}\n",
      "doc_map = {value:key for key, value in sf_data['doc-index-map'].iteritems()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading first-order features...\n",
        "\ttook 0.375 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def show_sfs(doc_index):\n",
      "    results = {}\n",
      "    for key, value in [sf_map[i].split('::') for i in sf_data['doc-sfs'][doc_map[doc_index]]]:\n",
      "        if not key in results: results[key] = set()\n",
      "        results[key].add(value)\n",
      "    keys = results.keys()\n",
      "    keys.sort()\n",
      "    print doc_map[doc_index]\n",
      "    for key in keys:\n",
      "        values = sort(list(results[key]))\n",
      "        print \"\\t%s: %s\" % (key, \"; \".join(values))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def doc_index(sf_data, doc):\n",
      "    return sf_data['doc-index-map'][doc]\n",
      "\n",
      "def sf_index(sf_data, sf):\n",
      "    return sf_data['sf-index-map'][sf]\n",
      "\n",
      "def get_docs(sf_data, i):\n",
      "    sf = sf_map[i]\n",
      "    return sf_data['sf-docs'][sf]\n",
      "\n",
      "def get_sfs(sf_data, i):\n",
      "    doc = doc_map[i]\n",
      "    return sf_data['doc-sfs'][doc]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def llr(sf_data, sums, i1, i2):\n",
      "    #i1 = sf_index(sf_data, sf1)\n",
      "    #i2 = sf_index(sf_data, sf2)\n",
      "    # compute actuaL cell frequencies\n",
      "    # - outer cells\n",
      "    ndd = float(sf_data['next-doc-index'])\n",
      "    npd = float(sums[0,i1])\n",
      "    ndp = float(sums[0,i2])\n",
      "    nnd = ndd - npd \n",
      "    ndn = ndd - ndp\n",
      "    # - inner cells\n",
      "    docs = [i for i in get_docs(sf_data, i1) if i in get_docs(sf_data, i2)]\n",
      "    npp = float(len(docs))\n",
      "    npn = npd - npp\n",
      "    nnp = ndp - npp\n",
      "    nnn = nnd - nnp\n",
      "    # compute (randomly) predicted cell frequencies\n",
      "    enn = nnd * ndn / ndd\n",
      "    enp = nnd * ndp / ndd\n",
      "    epn = npd * ndn / ndd\n",
      "    epp = npd * ndp / ndd\n",
      "    # compute log-likelihood ratio\n",
      "    result = 0.0\n",
      "    if nnn > 0: result += nnn * np.log(nnn / enn)\n",
      "    if nnp > 0: result += nnp * np.log(nnp / enp)\n",
      "    if npn > 0: result += npn * np.log(npn / epn)\n",
      "    if npp > 0: result += npp * np.log(npp / epp)\n",
      "    return 2.0 * result\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nrow2 = ncol2 = sf_data[\"next-sf-index\"]\n",
      "S2 = lil_matrix((nrow2, ncol2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.time()\n",
      "for i in range(nrow2):\n",
      "    for j in get_docs(sf_data, i):\n",
      "        for k in get_sfs(sf_data, j):\n",
      "            if S2[i,k] > 0: continue\n",
      "            else:\n",
      "                ratio = llr(sf_data, sums, i, k)\n",
      "                if ratio > 3.841: \n",
      "                    S2[i,k] = ratio\n",
      "                    S2[k,i] = ratio\n",
      "finish = time.time()\n",
      "print '\\ttook %0.3f s' % (finish-start)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttook 40.334 s\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.time()\n",
      "nrow = sf_data[\"next-doc-index\"]\n",
      "ncol = sf_data[\"next-sf-index\"]  \n",
      "X = lil_matrix((nrow, ncol))\n",
      "for i in range(nrow):\n",
      "    indices = get_sfs(sf_data, i)\n",
      "    X[i,:] = S2[indices,:].sum(axis=0) / len(indices)\n",
      "finish = time.time()\n",
      "print '\\ttook %0.3f s' % (finish-start)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttook 88.622 s\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn import metrics\n",
      "from sklearn.preprocessing import Normalizer\n",
      "nclusters = 35\n",
      "ncomponents = 100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate_kmeans(data, nclusters=nclusters, ncomponents=ncomponents):\n",
      "    lsa = TruncatedSVD(ncomponents)\n",
      "    Y = lsa.fit_transform(data)\n",
      "    Y = Normalizer(copy=False).fit_transform(Y)\n",
      "    km = KMeans(n_clusters=nclusters, init='k-means++', max_iter=100, n_init=10,verbose=True)\n",
      "    km.fit(Y)\n",
      "    np.savetxt(\"/tmp/data-%d.csv\" % ncomponents, Y, delimiter=\",\")\n",
      "    f = open(\"/tmp/labels.csv\", 'w')\n",
      "    for label in labels: f.write(\"%s\\n\" % label)\n",
      "    f.close()\n",
      "    print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_)) \n",
      "    print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
      "    print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
      "    return km"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(X, nclusters=nclusters, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialization complete\n",
        "Iteration  0, inertia 72.254\n",
        "Iteration  1, inertia 48.258\n",
        "Iteration  2, inertia 47.671\n",
        "Iteration  3, inertia 47.626\n",
        "Converged at iteration 3\n",
        "Initialization complete\n",
        "Iteration  0, inertia 70.516\n",
        "Iteration  1, inertia 49.268\n",
        "Iteration  2, inertia 49.127\n",
        "Converged at iteration 2\n",
        "Initialization complete\n",
        "Iteration  0, inertia 70.156\n",
        "Iteration  1, inertia 47.051\n",
        "Iteration  2, inertia 46.555\n",
        "Iteration  3, inertia 46.516\n",
        "Iteration  4, inertia 46.492\n",
        "Converged at iteration 4\n",
        "Initialization complete\n",
        "Iteration  0, inertia 70.697"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  1, inertia 48.375\n",
        "Iteration  2, inertia 47.953\n",
        "Iteration  3, inertia 47.637\n",
        "Iteration  4, inertia 47.372\n",
        "Iteration  5, inertia 47.108\n",
        "Converged at iteration 5\n",
        "Initialization complete\n",
        "Iteration  0, inertia 72.605\n",
        "Iteration  1, inertia 48.699\n",
        "Iteration  2, inertia 48.580\n",
        "Iteration  3, inertia 48.462\n",
        "Iteration  4, inertia 48.149\n",
        "Iteration  5, inertia 48.129\n",
        "Converged at iteration 5\n",
        "Initialization complete\n",
        "Iteration  0, inertia 71.704\n",
        "Iteration  1, inertia 50.447\n",
        "Iteration  2, inertia 50.149\n",
        "Converged at iteration 2\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 72.389\n",
        "Iteration  1, inertia 47.447\n",
        "Iteration  2, inertia 47.232\n",
        "Converged at iteration 2\n",
        "Initialization complete\n",
        "Iteration  0, inertia 71.805\n",
        "Iteration  1, inertia 48.597\n",
        "Iteration  2, inertia 48.460\n",
        "Iteration  3, inertia 48.412\n",
        "Converged at iteration 3\n",
        "Initialization complete\n",
        "Iteration  0, inertia 72.373\n",
        "Iteration  1, inertia 48.837\n",
        "Iteration  2, inertia 48.743\n",
        "Converged at iteration 2\n",
        "Initialization complete\n",
        "Iteration  0, inertia 74.196\n",
        "Iteration  1, inertia 47.421"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  2, inertia 47.365\n",
        "Iteration  3, inertia 47.331\n",
        "Converged at iteration 3\n",
        "Homogeneity: 0.850\n",
        "Completeness: 0.558\n",
        "V-measure: 0.674\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 91,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=10,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(S)\n",
      "evaluate_kmeans(X)\n",
      "evaluate_kmeans(Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialization complete\n",
        "Iteration  0, inertia 4624.000\n",
        "Iteration  1, inertia 3776.167\n",
        "Converged at iteration 1\n",
        "Homogeneity: 0.375\n",
        "Completeness: 0.402\n",
        "V-measure: 0.388\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 580705.204\n",
        "Iteration  1, inertia 409590.612"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  2, inertia 408134.827\n",
        "Converged at iteration 2\n",
        "Homogeneity: 0.611\n",
        "Completeness: 0.447\n",
        "V-measure: 0.516\n",
        "Initialization complete\n",
        "Iteration  0, inertia 101.562\n",
        "Iteration  1, inertia 67.670\n",
        "Iteration  2, inertia 66.250\n",
        "Iteration  3, inertia 65.561"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  4, inertia 65.191\n",
        "Iteration  5, inertia 65.158\n",
        "Converged at iteration 5\n",
        "Homogeneity: 0.826\n",
        "Completeness: 0.545\n",
        "V-measure: 0.657\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "km1.fit(S)\n",
      "km2.fit(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialization complete\n",
        "Iteration  0, inertia 4977.000\n",
        "Iteration  1, inertia 3860.653\n",
        "Iteration  2, inertia 3839.689\n",
        "Iteration  3, inertia 3838.463\n",
        "Iteration  4, inertia 3837.906\n",
        "Converged at iteration 4\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 588649.046\n",
        "Iteration  1, inertia 388515.383"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  2, inertia 385201.257\n",
        "Converged at iteration 2\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km1.labels_)) \n",
      "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km1.labels_))\n",
      "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km1.labels_))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Homogeneity: 0.460\n",
        "Completeness: 0.406\n",
        "V-measure: 0.432\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km2.labels_)) \n",
      "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km2.labels_))\n",
      "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km2.labels_))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Homogeneity: 0.665\n",
        "Completeness: 0.468\n",
        "V-measure: 0.550\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nrow = sf_data[\"next-doc-index\"]\n",
      "ncol = sf_data[\"next-sf-index\"]  \n",
      "labels = range(nrow)\n",
      "for key, value in sf_data['doc-index-map'].iteritems():\n",
      "    labels[value] = key.split('::')[0].split('-')[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsa = TruncatedSVD(ncomponents)\n",
      "Y = lsa.fit_transform(X)\n",
      "Y = Normalizer(copy=False).fit_transform(Y)\n",
      "print Y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(189, 100)\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}