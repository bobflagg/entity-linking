{
 "metadata": {
  "name": "clustering-feature-extractor"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd '/home/disambiguation/entity-linking/disambiguation/src/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/disambiguation/entity-linking/disambiguation/src\n"
       ]
      }
     ],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs\n",
      "import ConfigParser\n",
      "from data.domain import SUBTYPES\n",
      "import json as simplejson\n",
      "import numpy as np\n",
      "import optparse\n",
      "import os\n",
      "from scipy.sparse import csc_matrix, hstack, lil_matrix\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 215
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "home = '/home/disambiguation/'\n",
      "group = 'js'\n",
      "max_coreferences = 12"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 282
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_coreference_data(home, group, update=False):\n",
      "  start = time.time()\n",
      "  path = '%s/output/entity/%s/coreference-data.txt' % (home, group)\n",
      "  fp = codecs.open(path, 'r', 'UTF-8')\n",
      "  data = simplejson.load(fp)\n",
      "  fp.close()\n",
      "  nrow = data[\"next-mention-index\"]\n",
      "  ncol = data[\"next-sf-index\"]  \n",
      "  path = '%s/output/entity/%s/fof-sparse.npz' % (home, group)\n",
      "  nz_count = 0\n",
      "  if update or not os.path.exists(path):\n",
      "    print \"Updating first-order features...\"\n",
      "    coreference_map = {}\n",
      "    S = lil_matrix((nrow, ncol))\n",
      "    for mention_id, mention_index in data['mention-index-map'].iteritems():\n",
      "      coreferences = sorted(data['mention-sfs'][mention_id], key=lambda x: -x[1])\n",
      "      coreferences = coreferences[:max_coreferences]\n",
      "      coreference_map[mention_index] = coreferences\n",
      "      for sf_index, proximity, frequency in coreferences: \n",
      "          S[mention_index, sf_index] = 1.0\n",
      "          nz_count += 1\n",
      "    S = S.tocsc()\n",
      "    sums = S.sum(axis=0)\n",
      "    np.savez(path, S.data, S.indices, S.indptr, sums)\n",
      "    fp = codecs.open('%s/output/entity/%s/coreference-map.json' % (home, group), 'w', 'UTF-8')\n",
      "    simplejson.dump(coreference_map, fp, indent=4)\n",
      "    fp.close()\n",
      "  else: print \"Loading coreference data...\"  \n",
      "  npzfile = np.load(path)\n",
      "  S = csc_matrix((npzfile['arr_0'], npzfile['arr_1'], npzfile['arr_2']), shape=(nrow, ncol))\n",
      "  sums = npzfile['arr_3']\n",
      "  fp = codecs.open('%s/output/entity/%s/coreference-map.json' % (home, group), 'r', 'UTF-8')\n",
      "  coreference_map = simplejson.load(fp)\n",
      "  fp.close()\n",
      "  coreference_map = {int(key):value for key, value in coreference_map.iteritems()}\n",
      "  finish = time.time()\n",
      "  print '\\ttook %0.3f s' % (finish-start)\n",
      "  return data, coreference_map, S, sums, nz_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 283
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sf_data, coreference_map, S, sums, nz_count = get_coreference_data(home, group, update=True)\n",
      "sf_map = {value:key for key, value in sf_data['sf-index-map'].iteritems()}\n",
      "mention_map = {value:key for key, value in sf_data['mention-index-map'].iteritems()}\n",
      "print \"nz_count:\", nz_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Updating first-order features...\n",
        "\ttook 0.460 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nz_count: 2283\n"
       ]
      }
     ],
     "prompt_number": 284
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mention_map[5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 233,
       "text": [
        "u'js-16::960731-338_UEM::1'"
       ]
      }
     ],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nrow = sf_data[\"next-mention-index\"]\n",
      "ncol = sf_data[\"next-sf-index\"]  \n",
      "info = {}\n",
      "index_map = {}\n",
      "labels = range(nrow)\n",
      "for key, value in sf_data['mention-index-map'].iteritems():\n",
      "    folder, doc, occurrence = key.split('::') # js-8::970429-552_UEM::1\n",
      "    identifier = doc.split('-')[-1][:-4]\n",
      "    label = folder.split('-')[-1]\n",
      "    labels[value] = label\n",
      "    tag = \"%s-%s-%s\" % (label,identifier, occurrence)\n",
      "    info[value] = (folder, label, identifier, tag, key, value)\n",
      "    index_map[tag] = value\n",
      "f = open(\"/home/disambiguation/data/info.csv\", 'w')\n",
      "for folder, label, identifier, tag, key, value in info.values(): \n",
      "    f.write(\"%s,%s,%s,%s,%s,%d\\n\" % (folder, label, identifier, tag, key, value))\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def show_coreference_info(doc_index):\n",
      "    results = {}\n",
      "    \n",
      "    for key, value in [sf_map[i].split('::') for i in sf_data['doc-sfs'][doc_map[doc_index]]]:\n",
      "        if not key in results: results[key] = set()\n",
      "        results[key].add(value)\n",
      "    keys = results.keys()\n",
      "    keys.sort()\n",
      "    print doc_map[doc_index]\n",
      "    for key in keys:\n",
      "        print \"\\t%s\" % key\n",
      "        values = sort(list(results[key]))\n",
      "        for value in values: print \"\\t\\t%s\" % value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def show_coreference_info(mention_index):\n",
      "    results = {}\n",
      "    for sf_index, _, _ in coreference_map[mention_index]:\n",
      "        sf = sf_map[sf_index]\n",
      "        key, value = sf.split('::')\n",
      "        if not key in results: results[key] = []\n",
      "        results[key].append(value)\n",
      "    keys = results.keys()\n",
      "    keys.sort()\n",
      "    for key in keys:\n",
      "        print \"\\t%s\" % key\n",
      "        for value in results[key]: print \"\\t\\t%s\" % value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 285
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show_coreference_info(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tCOMPANY\n",
        "\t\tgm\n",
        "\t\tgeneral motors\n",
        "\t\tbloomberg general motors corp.\n",
        "\tGEO\n",
        "\t\trochester, michigan\n",
        "\t\tu.s.\n",
        "\t\tlordstown, ohio\n",
        "\tLOCATION\n",
        "\t\tpontiac grand prix\n",
        "\tORGANIZATION\n",
        "\t\tgm\n",
        "\t\tsaturn\n",
        "\t\tunited auto workers\n",
        "\tPERSON\n",
        "\t\tsmith\n",
        "\t\tal alli\n"
       ]
      }
     ],
     "prompt_number": 266
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sf_map[87]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 267,
       "text": [
        "u'GEO::u.s.'"
       ]
      }
     ],
     "prompt_number": 267
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for key in [key for key in index_map.keys() if key.startswith('0-')]:\n",
      "    print key\n",
      "    show_coreference_info(index_map[key])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0-274-1\n",
        "\tGEO\n",
        "\t\tnorth america\n",
        "\t\tjamestown\n",
        "\t\tjames river\n",
        "\t\tcape henry\n",
        "\t\tyorktown\n",
        "\t\tnorfolk\n",
        "\t\tcavalier hotel\n",
        "\t\tvirginia beach\n",
        "\t\tnorth carolina\n",
        "\tLOCATION\n",
        "\t\tgrasse\n",
        "\tPERSON\n",
        "\t\tfrancois joseph paul\n",
        "\t\tanne county\n",
        "0-114-1\n",
        "\tGEO\n",
        "\t\tengland\n",
        "\t\tlondon\n",
        "\t\tamerica\n",
        "\t\tcanada\n",
        "\t\taustralia\n",
        "\t\tstates\n",
        "\t\tpocahontas\n",
        "\t\tgravesend\n",
        "\t\tthames\n",
        "\tORGANIZATION\n",
        "\t\tchurch of st. george\n",
        "\tPERSON\n",
        "\t\tdavid willey\n",
        "\t\tjames i\n",
        "0-192-1\n",
        "\tCOMPANY\n",
        "\t\ttupperware\n",
        "\t\tthe palm beach post\n",
        "\tGEO\n",
        "\t\tpocahontas\n",
        "\tLOCATION\n",
        "\t\tana\n",
        "\t\tpalm beach post\n",
        "\tPERSON\n",
        "\t\tnancy bivona\n",
        "\t\tkatie\n",
        "\t\tmrs. levine\n",
        "\t\tbivona\n",
        "\t\tyadi cox\n",
        "\t\tmiss mary\n",
        "\t\temily j. minor\n",
        "0-528-1\n",
        "\tGEO\n",
        "\t\tjamestown\n",
        "\t\tkansas\n",
        "\t\tflorida\n",
        "\t\talbany, n.y.\n",
        "\t\tconnecticut\n",
        "\t\talton, ill.\n",
        "\tORGANIZATION\n",
        "\t\tagriculture department farmers\n",
        "\t\tdiospyros virginiana\n",
        "\t\tamerican and oriental persimmon\n",
        "\t\tamerican persimmon\n",
        "\tPERSON\n",
        "\t\tw.f. fletcher\n",
        "\t\tgarretson\n",
        "0-638-1\n",
        "\tGEO\n",
        "\t\tdogpatch\n",
        "\t\tcabin john\n",
        "\t\tlittle falls\n",
        "\t\twashington\n",
        "\t\tgreat falls\n",
        "\t\tpotomac\n",
        "\t\tluger\n",
        "\tLOCATION\n",
        "\t\tcabin\n",
        "\tORGANIZATION\n",
        "\t\tmacarthur boulevard west\n",
        "\tPERSON\n",
        "\t\tmrs. riner\n",
        "\t\tbess truman\n",
        "\t\tmrs. riner\n",
        "0-638-2\n",
        "\tGEO\n",
        "\t\tlittle falls\n",
        "\t\twashington\n",
        "\t\tgreat falls\n",
        "\t\tcabin john\n",
        "\t\tpotomac\n",
        "\t\tdogpatch\n",
        "\t\tgatehouse\n",
        "\tLOCATION\n",
        "\t\tcabin\n",
        "\tORGANIZATION\n",
        "\t\tmacarthur boulevard west\n",
        "\tPERSON\n",
        "\t\tmrs. riner\n",
        "\t\tbess truman\n",
        "\t\tmrs. riner\n",
        "0-458-1\n",
        "\tCOMPANY\n",
        "\t\tnyt\n",
        "\tGEO\n",
        "\t\tpocahontas\n",
        "\t\tbilik\n",
        "\tORGANIZATION\n",
        "\t\tmadison square garden\n",
        "\tPERSON\n",
        "\t\tarmen saakian\n",
        "\t\tgovernor ratcliffe\n",
        "\t\tsergie petrovski\n",
        "\t\twiggins\n",
        "\t\tdoug barnhart\n",
        "\t\tratcliff\n",
        "\t\tship donahue\n",
        "\t\tmeeko\n",
        "0-464-1\n",
        "\tGEO\n",
        "\t\tpocahontas\n",
        "\t\tnew jersey\n",
        "\t\tparamus\n",
        "\t\tbucharest, romania\n",
        "\t\twestern romania\n",
        "\t\tarad\n",
        "\t\thungary\n",
        "\tPERSON\n",
        "\t\tanita garlick\n",
        "\t\tdr. nylite\n",
        "\t\tdaniel ranca\n",
        "\t\ttita and belu\n",
        "\t\tgeorge carlin\n",
        "0-171-1\n",
        "\tGEO\n",
        "\t\tamerica\n",
        "\t\tvirginia\n",
        "\t\tjamestown\n",
        "\t\tvirginia beach\n",
        "\t\tcolonial williamsburg\n",
        "\t\to'hare international airport\n",
        "\t\twilliamsburg\n",
        "\t\tchicago\n",
        "\t\tatlanta\n",
        "\t\tkansas city\n",
        "\tORGANIZATION\n",
        "\t\tnational society of newspaper columnists\n",
        "\t\tnational society of newspaper\n",
        "0-505-1\n",
        "\tGEO\n",
        "\t\tsherman oaks\n",
        "\t\tpowhatan\n",
        "\t\tvirginia\n",
        "\t\tpocahontas\n",
        "\t\tamerica\n",
        "\t\tcolumbus\n",
        "\t\tchina\n",
        "\tPERSON\n",
        "\t\tk caruso\n",
        "\t\tpamela anderson esque\n",
        "\t\tpepe le pew\n",
        "\t\tjames fenimore cooper\n",
        "\t\tcarnes\n",
        "0-375-1\n",
        "\tCOMPANY\n",
        "\t\tdisney\n",
        "\tGEO\n",
        "\t\tpocahontas\n",
        "\tLOCATION\n",
        "\t\tbeast\n",
        "\tORGANIZATION\n",
        "\t\torion\n",
        "\tPERSON\n",
        "\t\tirene bedard\n",
        "\t\tmel gibson\n",
        "\t\teric goldberg\n",
        "\t\tmike gabriel\n",
        "\t\tstephen schwartz\n",
        "\t\tlion king\n",
        "\t\talan menken\n",
        "\t\trobin hood\n",
        "0-295-2\n",
        "\tCOMPANY\n",
        "\t\tdisney\n",
        "\tGEO\n",
        "\t\tpocahontas\n",
        "\t\tcalifornia\n",
        "\t\thamlet\n",
        "\tORGANIZATION\n",
        "\t\tnice\n",
        "\t\tgoofy\n",
        "\t\tshakespeare\n",
        "\tPERSON\n",
        "\t\tmax\n",
        "\t\tlewis carroll\n",
        "\t\tkevin lauderdale\n",
        "\t\tphillip\n",
        "\t\trobin hood\n",
        "0-295-1\n",
        "\tCOMPANY\n",
        "\t\tdisney\n",
        "\tGEO\n",
        "\t\twinnie\n",
        "\t\talley cat\n",
        "\t\to'malley\n",
        "\tORGANIZATION\n",
        "\t\tduchess\n",
        "\tPERSON\n",
        "\t\trobin\n",
        "\t\terrol flynn\n",
        "\t\trobin hood\n",
        "\t\tkevin costner\n",
        "\t\teva gabor\n",
        "\t\tphil harris\n",
        "\t\tsebastian cabot\n",
        "0-222-1\n",
        "\tGEO\n",
        "\t\tstorrs, conn.\n",
        "\t\tnew england\n",
        "\t\tmason dixon\n",
        "\t\tvermont\n",
        "\t\tgreen mountain\n",
        "\t\tmaine\n",
        "\t\tnew hampshire\n",
        "\tLOCATION\n",
        "\t\tnew englanders\n",
        "\t\tnew englanders\n",
        "\tORGANIZATION\n",
        "\t\troper center for public policy research\n",
        "\t\tgreen mountain state\n",
        "\tPERSON\n",
        "\t\tchris barnes\n",
        "0-658-1\n",
        "\tCOMPANY\n",
        "\t\tvirginia company\n",
        "\tGEO\n",
        "\t\ttidewater virginia\n",
        "\t\tjamestown\n",
        "\t\tunited states\n",
        "\tORGANIZATION\n",
        "\t\tsmith\n",
        "\t\tnational geographic society\n",
        "\t\tassociation for the preservation of virginia antiquities\n",
        "\tPERSON\n",
        "\t\tjames i. among\n",
        "\t\tjames fort\n",
        "\t\tkelso\n",
        "\t\twilliam kelso\n",
        "\t\tedward everett\n",
        "0-500-1\n",
        "\tCOMPANY\n",
        "\t\tnew york times\n",
        "\tGEO\n",
        "\t\tu.s.\n",
        "\t\tjericho\n",
        "\tLOCATION\n",
        "\t\tnew york\n",
        "\tORGANIZATION\n",
        "\t\tsam\n",
        "\tPERSON\n",
        "\t\tdick\n",
        "\t\therman melville\n",
        "\t\tcaptain peleg\n",
        "\t\tahab\n",
        "\t\tsteve johnson\n",
        "\t\tdavid richards\n",
        "\t\tjeremiah\n",
        "0-459-1\n",
        "\tGEO\n",
        "\t\tpocahontas\n",
        "\t\tnew jersey\n",
        "\t\tparamus\n",
        "\t\tbucharest, romania\n",
        "\t\twestern romania\n",
        "\t\tarad\n",
        "\t\thungary\n",
        "\tPERSON\n",
        "\t\tanita garlick\n",
        "\t\tdr. nylite\n",
        "\t\tdaniel ranca\n",
        "\t\ttita and belu\n",
        "\t\tgeorge carlin\n",
        "0-938-1\n",
        "\tEDUCATIONAL\n",
        "\t\temory university\n",
        "\tGEO\n",
        "\t\tpocahontas\n",
        "\t\tgeorgia\n",
        "\t\tatlanta\n",
        "\t\tdecatur\n",
        "\t\tpsalms\n",
        "\tPERSON\n",
        "\t\tdresch\n",
        "\t\twhen amy richter\n",
        "\t\tamy richter case\n",
        "\t\tfred dresch\n",
        "\t\trichter\n",
        "\t\tharris corry\n",
        "0-225-1\n",
        "\tCOMPANY\n",
        "\t\twalt disney co.\n",
        "\tGEO\n",
        "\t\tpocahontas\n",
        "\t\tengland\n",
        "\t\tanaheim\n",
        "\t\tphoenix\n",
        "\t\tamerica west arena\n",
        "\tORGANIZATION\n",
        "\t\tstanley cup\n",
        "\t\tdisney\n",
        "\tSPORTS\n",
        "\t\tmighty ducks\n",
        "\t\tducks\n",
        "\t\twestern conference\n",
        "\t\tcoyotes\n",
        "0-380-1\n",
        "\tGEO\n",
        "\t\tlos angeles\n",
        "\t\tpocahontas\n",
        "\t\tlos angeles\n",
        "\t\tsherman oaks\n",
        "\tORGANIZATION\n",
        "\t\tnakoma\n",
        "\t\tdonn wilkerson of sherman oaks\n",
        "\tPERSON\n",
        "\t\tarmen saakian\n",
        "\t\tsergei petrovski\n",
        "\t\tlarissa zamotina\n",
        "\t\tsarah kawahara\n",
        "\t\tcindy stuart\n",
        "\t\tng\n",
        "0-406-1\n",
        "\tCOMPANY\n",
        "\t\tchrysler plymouth rock\n",
        "\tGEO\n",
        "\t\tplymouth rock\n",
        "\t\tpilgrims\n",
        "\t\tjamestown\n",
        "\t\tlordy\n",
        "\t\tvirginia\n",
        "\t\tnew world\n",
        "\t\tjames river\n",
        "\t\tjames river\n",
        "\t\tcolonial williamsburg\n",
        "\tORGANIZATION\n",
        "\t\tassociation for the preservation of virginia antiquities\n",
        "\tPERSON\n",
        "\t\tjames fort\n"
       ]
      }
     ],
     "prompt_number": 317
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mention_index(sf_data, mention):\n",
      "    return sf_data['mention-index-map'][mention]\n",
      "\n",
      "def sf_index(sf_data, sf):\n",
      "    return sf_data['sf-index-map'][sf]\n",
      "\n",
      "def get_mentions(sf_data, coreference_map, i):\n",
      "    sf = sf_map[i]\n",
      "    return [j for j in sf_data['sf-mentions'][sf] if i in [index for index, _, _ in coreference_map[j]]]\n",
      "\n",
      "def get_sfs(coreference_map, i):\n",
      "    #mention = mention_map[i]\n",
      "    #return sf_data['mention-sfs'][mention]\n",
      "    return [sf for sf, _, _ in coreference_map[i]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 286
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_mentions(sf_data, coreference_map, 122)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 247,
       "text": [
        "[3, 10, 69, 75, 104]"
       ]
      }
     ],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sf = sf_map[10]\n",
      "print sf\n",
      "print coreference_map[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GEO::san francisco bay area\n",
        "[[13, 1.0, 1], [25, 1.0, 7], [33, 1.0, 1], [11, 0.943, 1], [26, 0.943, 1], [29, 0.943, 1], [5, 0.914, 1], [24, 0.914, 1], [9, 0.886, 5], [17, 0.886, 1], [2, 0.857, 1], [4, 0.857, 2], [18, 0.857, 1], [19, 0.829, 1], [21, 0.829, 1], [23, 0.829, 1], [6, 0.8, 4], [16, 0.771, 1], [31, 0.771, 1], [0, 0.714, 1], [8, 0.714, 2], [7, 0.686, 1], [14, 0.686, 1], [3, 0.629, 1], [1, 0.6, 1], [12, 0.6, 1], [15, 0.6, 1], [9, 0.571, 1], [22, 0.514, 1], [36, 0.343, 1], [27, 0.314, 1], [28, 0.286, 1], [32, 0.286, 1], [20, 0.229, 1], [30, 0.229, 1], [34, 0.229, 1], [35, 0.229, 1], [9, 0.2, 1], [10, 0.2, 1]]\n"
       ]
      }
     ],
     "prompt_number": 240
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def llr(sf_data, coreference_map, sums, i1, i2):\n",
      "    #i1 = sf_index(sf_data, sf1)\n",
      "    #i2 = sf_index(sf_data, sf2)\n",
      "    # compute actuaL cell frequencies\n",
      "    # - outer cells\n",
      "    ndd = float(sf_data['next-mention-index'])\n",
      "    npd = float(sums[0,i1])\n",
      "    ndp = float(sums[0,i2])\n",
      "    nnd = ndd - npd \n",
      "    ndn = ndd - ndp\n",
      "    # - inner cells\n",
      "    mentions = [i for i in get_mentions(sf_data, coreference_map, i1) if i in get_mentions(sf_data, coreference_map, i2)]\n",
      "    npp = float(len(mentions))\n",
      "    npn = npd - npp\n",
      "    nnp = ndp - npp\n",
      "    nnn = nnd - nnp\n",
      "    # compute (randomly) predicted cell frequencies\n",
      "    enn = nnd * ndn / ndd\n",
      "    enp = nnd * ndp / ndd\n",
      "    epn = npd * ndn / ndd\n",
      "    epp = npd * ndp / ndd\n",
      "    #print npd, ndp, npp, ndd\n",
      "    # compute log-likelihood ratio\n",
      "    result = 0.0\n",
      "    if nnn > 0: result += nnn * np.log(nnn / enn)\n",
      "    if nnp > 0: result += nnp * np.log(nnp / enp)\n",
      "    if npn > 0: result += npn * np.log(npn / epn)\n",
      "    if npp > 0: result += npp * np.log(npp / epp)\n",
      "    return 2.0 * result\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 287
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "llr(sf_data, coreference_map, sums, 1,1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 249,
       "text": [
        "12.520190058617681"
       ]
      }
     ],
     "prompt_number": 249
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chi_square_cut_off = 3.841\n",
      "#chi_square_cut_off = 6.635\n",
      "#chi_square_cut_off = 0.01\n",
      "nrow2 = ncol2 = sf_data[\"next-sf-index\"]\n",
      "S2 = lil_matrix((nrow2, ncol2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 294
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_mentions(sf_data, coreference_map, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 251,
       "text": [
        "[0]"
       ]
      }
     ],
     "prompt_number": 251
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.time()\n",
      "for i in range(nrow2):\n",
      "    for j in get_mentions(sf_data, coreference_map, i):\n",
      "        for k in get_sfs(coreference_map, j):\n",
      "            if S2[i,k] > 0: continue\n",
      "            else:\n",
      "                ratio = llr(sf_data, coreference_map, sums, i, k)\n",
      "                if ratio > chi_square_cut_off: \n",
      "                    S2[i,k] = ratio\n",
      "                    S2[k,i] = ratio\n",
      "finish = time.time()\n",
      "print '\\ttook %0.3f s' % (finish-start)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttook 5.786 s\n"
       ]
      }
     ],
     "prompt_number": 295
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.time()\n",
      "nrow = sf_data[\"next-mention-index\"]\n",
      "ncol = sf_data[\"next-sf-index\"]  \n",
      "X = lil_matrix((nrow, ncol))\n",
      "for i in range(nrow):\n",
      "    indices = get_sfs(coreference_map, i)\n",
      "    X[i,:] = S2[indices,:].sum(axis=0) / len(indices)\n",
      "finish = time.time()\n",
      "print '\\ttook %0.3f s' % (finish-start)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttook 32.779 s\n"
       ]
      }
     ],
     "prompt_number": 296
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn import metrics\n",
      "from sklearn.preprocessing import Normalizer\n",
      "nclusters = 35\n",
      "ncomponents = 58"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 297
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate_kmeans(data, nclusters=nclusters, ncomponents=ncomponents):\n",
      "    num_rows, num_cols = data.shape\n",
      "    print num_rows, num_cols\n",
      "    if num_cols > ncomponents:\n",
      "        lsa = TruncatedSVD(ncomponents)\n",
      "        Y = lsa.fit_transform(data)\n",
      "        Y = Normalizer(copy=False).fit_transform(Y)\n",
      "    else: \n",
      "        Y = data.todense()\n",
      "        ncomponents = num_cols\n",
      "    km = KMeans(n_clusters=nclusters, init='k-means++', max_iter=100, n_init=1,verbose=True)\n",
      "    km.fit(Y)\n",
      "    np.savetxt(\"/home/disambiguation/data/data-%d.csv\" % ncomponents, Y, delimiter=\",\")\n",
      "    print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_)) \n",
      "    print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
      "    print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
      "    return km"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 298
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(S, nclusters=35, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "193 3747\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 123.068\n",
        "Iteration  1, inertia 79.635\n",
        "Iteration  2, inertia 78.250\n",
        "Converged at iteration 2\n",
        "Homogeneity: 0.824\n",
        "Completeness: 0.522\n",
        "V-measure: 0.640\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 299,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 299
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = evaluate_kmeans(X, nclusters=35, ncomponents=60)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "193 3747\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 86.215\n",
        "Iteration  1, inertia 58.073\n",
        "Iteration  2, inertia 57.009\n",
        "Iteration  3, inertia 56.725\n",
        "Iteration  4, inertia 56.698\n",
        "Converged at iteration 4\n",
        "Homogeneity: 0.838\n",
        "Completeness: 0.553\n",
        "V-measure: 0.666\n"
       ]
      }
     ],
     "prompt_number": 304
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result.labels_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 162,
       "text": [
        "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0])"
       ]
      }
     ],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(hstack([S,X]), nclusters=35, ncomponents=400)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "193 7494\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 115.967\n",
        "Iteration  1, inertia 74.877\n",
        "Iteration  2, inertia 73.237\n",
        "Iteration  3, inertia 73.035\n",
        "Converged at iteration 3\n",
        "Homogeneity: 0.812"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Completeness: 0.537\n",
        "V-measure: 0.646\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 311,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 311
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Investigate Topic Features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_topic_data(home, group, update=False):\n",
      "  start = time.time()\n",
      "  path = '%s/output/entity/%s/topic-data.json' % (home, group)\n",
      "  fp = codecs.open(path, 'r', 'UTF-8')\n",
      "  topic_data = simplejson.load(fp)\n",
      "  fp.close()\n",
      "  ntopics = topic_data[\"number-of-topics\"]  \n",
      "  TS = lil_matrix((nrow, ntopics))\n",
      "  for key, value in topic_data['document_topics'].iteritems():\n",
      "    for doc, topics in value.iteritems():\n",
      "      doc_key = \"%s::%s_UEM\" % (key, doc[:-9])\n",
      "      i = sf_data['doc-index-map'][doc_key]\n",
      "      for t, w, _ in topics: TS[i,t] = w\n",
      "  TS = TS.tocsc()\n",
      "  finish = time.time()\n",
      "  print '\\ttook %0.3f s' % (finish-start)\n",
      "  return topic_data, TS"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_data, TS = get_topic_data(home, group, update=False)\n",
      "print TS.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttook 0.007 s\n",
        "(189, 12)\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sf_data['doc-index-map'][\"js-13::960920-114_UEM\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TS[2,6]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "0.0"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(TS, nclusters=35, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 12\n",
        "Initialization complete\n",
        "Iteration  0, inertia 3.469\n",
        "Iteration  1, inertia 2.391\n",
        "Iteration  2, inertia 2.377\n",
        "Iteration  3, inertia 2.374\n",
        "Converged at iteration 3\n",
        "Homogeneity: 0.666\n",
        "Completeness: 0.469\n",
        "V-measure: 0.550\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(hstack([S,TS]), nclusters=35, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 3739\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 96.271\n",
        "Iteration  1, inertia 65.665\n",
        "Iteration  2, inertia 65.314\n",
        "Iteration  3, inertia 65.008\n",
        "Converged at iteration 3\n",
        "Homogeneity: 0.759\n",
        "Completeness: 0.481\n",
        "V-measure: 0.589\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(hstack([X,TS]), nclusters=35, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 3739\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 72.485\n",
        "Iteration  1, inertia 47.878\n",
        "Iteration  2, inertia 47.622\n",
        "Iteration  3, inertia 47.581\n",
        "Converged at iteration 3\n",
        "Homogeneity: 0.839\n",
        "Completeness: 0.545\n",
        "V-measure: 0.660\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_kmeans(hstack([S,X,TS]), nclusters=35, ncomponents=58)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "189 7466\n",
        "Initialization complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration  0, inertia 68.661\n",
        "Iteration  1, inertia 46.211\n",
        "Iteration  2, inertia 46.029\n",
        "Iteration  3, inertia 45.996\n",
        "Converged at iteration 3\n",
        "Homogeneity: 0.862\n",
        "Completeness: 0.563\n",
        "V-measure: 0.681\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=35, n_init=1,\n",
        "    n_jobs=1, precompute_distances=True, random_state=None, tol=0.0001,\n",
        "    verbose=True)"
       ]
      }
     ],
     "prompt_number": 46
    }
   ],
   "metadata": {}
  }
 ]
}